{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Programación II: Introducción a Pandas y Polars**\n",
    "\n",
    "### **¿Qué es Pandas?**\n",
    "\n",
    "`Pandas` es una biblioteca de Python ampliamente utilizada para la manipulación y análisis de datos estructurados. Es una herramienta poderosa para trabajar con tablas (DataFrames) y series (Series), proporcionando una interfaz intuitiva para realizar operaciones comunes como:\n",
    "- Filtrar datos.\n",
    "- Combinar tablas.\n",
    "- Manejar valores nulos.\n",
    "- Calcular estadísticas descriptivas.\n",
    "\n",
    "Pandas está construido sobre NumPy, lo que lo hace eficiente para manejar grandes volúmenes de datos.\n",
    "\n",
    "---\n",
    "\n",
    "### **Características Clave de Pandas**\n",
    "1. **Estructuras de Datos Flexibles**:\n",
    "   - `Series`: Array unidimensional con etiquetas (similar a una columna en Excel).\n",
    "   - `DataFrame`: Tabla bidimensional etiquetada (similar a una hoja de cálculo o tabla de SQL).\n",
    "\n",
    "2. **Soporte para Diversos Formatos de Archivo**:\n",
    "   - Leer y escribir datos en formatos como CSV, Excel, JSON, Parquet, etc.\n",
    "\n",
    "3. **Manipulación y Transformación**:\n",
    "   - Filtrado, agrupación, pivot, y más.\n",
    "\n",
    "4. **Compatibilidad**:\n",
    "   - Integración perfecta con otras bibliotecas como NumPy, Matplotlib y Scikit-learn.\n",
    "\n",
    "---\n",
    "\n",
    "### **¿Qué es Polars?**\n",
    "\n",
    "`Polars` es una biblioteca emergente para el manejo de DataFrames, conocida por su velocidad y eficiencia. A diferencia de Pandas, Polars utiliza paralelización y evaluación tardía para optimizar el rendimiento, especialmente en grandes volúmenes de datos.\n",
    "\n",
    "---\n",
    "\n",
    "### **Diferencias Clave entre Pandas y Polars**\n",
    "\n",
    "| **Característica**          | **Pandas**                       | **Polars**                                      |\n",
    "|-----------------------------|-----------------------------------|------------------------------------------------|\n",
    "| **Velocidad**               | Buena para datasets pequeños.    | Excelente para grandes volúmenes de datos.     |\n",
    "| **Ejecución**               | Operaciones inmediatas.           | Evaluación tardía y paralelización.            |\n",
    "| **Memoria**                 | Consume más memoria.             | Ligero y eficiente en memoria.                |\n",
    "| **Sintaxis**                | Más simple para principiantes.   | Similar a PySpark, orientada a SQL.            |\n",
    "\n",
    "---\n",
    "\n",
    "### **¿Por qué Aprender Pandas y Polars?**\n",
    "\n",
    "Ambas bibliotecas son fundamentales para el análisis de datos moderno:\n",
    "\n",
    "- **Pandas** es ideal para trabajar en notebooks y manejar datasets pequeños o medianos.\n",
    "- **Polars** se destaca en proyectos donde el rendimiento y la escalabilidad son prioritarios.\n",
    "\n",
    "En este notebook, exploraremos las capacidades de ambas bibliotecas, sus similitudes, diferencias, y cómo aprovecharlas en diferentes escenarios de análisis de datos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar la librería\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **1. Estructuras de Datos en Pandas**\n",
    "\n",
    "Pandas ofrece dos estructuras de datos principales para trabajar de manera eficiente con datos:\n",
    "\n",
    "1. **Series**: Un array unidimensional con etiquetas.\n",
    "2. **DataFrames**: Tablas bidimensionales que combinan múltiples Series.\n",
    "\n",
    "En esta sección, nos centraremos en las **Series**, explorando su creación, indexación y las operaciones básicas que se pueden realizar con ellas.\n",
    "\n",
    "---\n",
    "\n",
    "## **1.1. ¿Qué es una Serie?**\n",
    "\n",
    "Una `Serie` en Pandas es un array unidimensional que combina los siguientes elementos:\n",
    "- **Datos:** Pueden ser de cualquier tipo (números, cadenas, etc.).\n",
    "- **Índices:** Etiquetas asociadas a cada dato, que permiten un acceso más intuitivo.\n",
    "\n",
    "Es similar a:\n",
    "- Un array de NumPy, pero con etiquetas.\n",
    "- Una columna en un DataFrame.\n",
    "\n",
    "Las Series son ideales para representar variables individuales o listas con semántica adicional.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serie de ejemplo:\n",
      "0    0.25\n",
      "1    0.50\n",
      "2    0.75\n",
      "3    1.00\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Crear una Serie de ejemplo\n",
    "serie = pd.Series([0.25, 0.5, 0.75, 1.0])\n",
    "\n",
    "# Imprimir la Serie\n",
    "print(\"Serie de ejemplo:\")\n",
    "print(serie)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **1.2. Índices en las Series**\n",
    "\n",
    "Cada elemento de una Serie tiene un índice asociado. Estos índices pueden ser:\n",
    "1. **Posicionales:** Similar al acceso en listas o arrays.\n",
    "2. **Etiquetados:** Personalizados para facilitar el acceso a los datos.\n",
    "\n",
    "Por defecto, Pandas asigna índices numéricos consecutivos (0, 1, 2...)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elemento en la posición 2: 0.75\n",
      "Serie con índices personalizados:\n",
      "A    0.25\n",
      "B    0.50\n",
      "C    0.75\n",
      "D    1.00\n",
      "dtype: float64\n",
      "Elemento con etiqueta 'B': 0.5\n"
     ]
    }
   ],
   "source": [
    "# Acceso por índice posicional\n",
    "print(\"Elemento en la posición 2:\", serie[2])\n",
    "\n",
    "# Acceso por índice personalizado\n",
    "serie.index = ['A', 'B', 'C', 'D']\n",
    "print(\"Serie con índices personalizados:\")\n",
    "print(serie)\n",
    "\n",
    "# Acceso usando etiquetas\n",
    "print(\"Elemento con etiqueta 'B':\", serie['B'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1.3. Operaciones con Series**\n",
    "\n",
    "Las Series permiten realizar operaciones matemáticas, de comparación y transformación directamente sobre sus datos. Estas operaciones son vectorizadas, lo que significa que se aplican a todos los elementos de la Serie de manera eficiente.\n",
    "\n",
    "---\n",
    "\n",
    "### **¿Cuándo usar métodos de Pandas vs NumPy?**\n",
    "\n",
    "- **Métodos de Pandas (`serie.method()`):**\n",
    "  - Si trabajas con datos indexados que requieren conservar la relación entre índice y valor.\n",
    "  - Cuando necesitas métodos diseñados específicamente para Series, como `value_counts()` o `describe()`.\n",
    "\n",
    "- **Métodos de NumPy (`np.method(serie)`):**\n",
    "  - Si buscas un enfoque más eficiente para cálculos puramente numéricos, donde el índice no sea relevante.\n",
    "  - Cuando necesites aplicar funciones avanzadas de NumPy no disponibles directamente en Pandas.\n",
    "\n",
    "---\n",
    "\n",
    "### **1.3.1. Operaciones Matemáticas con Series**\n",
    "\n",
    "Las Series de Pandas permiten realizar operaciones matemáticas de manera eficiente y vectorizada, aplicando la operación a cada elemento de la Serie sin necesidad de bucles explícitos.\n",
    "\n",
    "#### **¿Qué hace esto útil?**\n",
    "1. **Eficiencia:** Las operaciones son rápidas y están optimizadas gracias a la implementación subyacente en NumPy.\n",
    "2. **Compatibilidad:** Las operaciones mantienen la estructura de la Serie, incluyendo sus índices, lo que facilita el análisis de datos.\n",
    "3. **Flexibilidad:** Puedes usar operaciones estándar de Python, métodos de Pandas o funciones de NumPy.\n",
    "\n",
    "#### **Tipos de Operaciones Matemáticas:**\n",
    "1. **Operaciones Aritméticas Básicas**: Suma, resta, multiplicación, división, etc.\n",
    "2. **Operaciones Relativas**: Potencias, raíces cuadradas, etc.\n",
    "3. **Redondeo y Truncamiento**: Operaciones para manejar la precisión de los datos.\n",
    "\n",
    "En esta sección, exploraremos las principales operaciones matemáticas con Series y explicaremos su utilidad con ejemplos prácticos.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Operaciones Básicas**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Suma (`+` o `add`)**\n",
    "Permite sumar un escalar o los elementos de dos Series. Se utiliza para ajustar valores o realizar combinaciones entre datos.\n",
    "\n",
    "**Definición:**  \n",
    "`serie + valor` o `serie.add(valor)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serie original:\n",
      " 0    1\n",
      "1    2\n",
      "2    3\n",
      "3    4\n",
      "dtype: int64\n",
      "Suma con escalar:\n",
      " 0    11\n",
      "1    12\n",
      "2    13\n",
      "3    14\n",
      "dtype: int64\n",
      "Suma entre Series:\n",
      " 0    11\n",
      "1    22\n",
      "2    33\n",
      "3    44\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Suma de un escalar\n",
    "serie = pd.Series([1, 2, 3, 4])\n",
    "suma_escalar = serie + 10\n",
    "\n",
    "# Suma de dos Series\n",
    "otra_serie = pd.Series([10, 20, 30, 40])\n",
    "suma_series = serie + otra_serie\n",
    "\n",
    "# Suma con un escalar (add)\n",
    "suma_escalar = serie.add(10)\n",
    "\n",
    "# Suma entre Series (add)\n",
    "suma_series = serie.add(otra_serie)\n",
    "\n",
    "print(\"Suma con escalar:\\n\", suma_escalar)\n",
    "print(\"Suma entre Series:\\n\", suma_series)\n",
    "\n",
    "\n",
    "print(\"Serie original:\\n\", serie)\n",
    "print(\"Suma con escalar:\\n\", suma_escalar)\n",
    "print(\"Suma entre Series:\\n\", suma_series)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Resta (`-` o `subtract`)**\n",
    "Permite restar un escalar o los elementos de dos Series. Útil para calcular diferencias o ajustar valores.\n",
    "\n",
    "**Definición:**  \n",
    "`serie - valor` o `serie.subtract(valor)`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resta de un escalar (operador -)\n",
    "resta_escalar_op = serie - 2\n",
    "\n",
    "# Resta de dos Series (operador -)\n",
    "resta_series_op = serie - otra_serie\n",
    "\n",
    "# Resta con un escalar (subtract)\n",
    "resta_escalar = serie.subtract(2)\n",
    "\n",
    "# Resta entre Series (subtract)\n",
    "resta_series = serie.subtract(otra_serie)\n",
    "\n",
    "print(\"Serie original:\\n\", serie)\n",
    "print(\"Resta con escalar (operador -):\\n\", resta_escalar_op)\n",
    "print(\"Resta entre Series (operador -):\\n\", resta_series_op)\n",
    "print(\"Resta con escalar (subtract):\\n\", resta_escalar)\n",
    "print(\"Resta entre Series (subtract):\\n\", resta_series)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Multiplicación (`*` o `multiply`)**\n",
    "Realiza la multiplicación elemento a elemento en una Serie. Ideal para escalas o cálculos proporcionales.\n",
    "\n",
    "**Definición:**  \n",
    "`serie * valor` o `serie.multiply(valor)`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiplicación por un escalar (operador *)\n",
    "multiplicacion_escalar_op = serie * 3\n",
    "\n",
    "# Multiplicación entre Series (operador *)\n",
    "multiplicacion_series_op = serie * otra_serie\n",
    "\n",
    "# Multiplicación con un escalar (multiply)\n",
    "multiplicacion_escalar = serie.multiply(3)\n",
    "\n",
    "# Multiplicación entre Series (multiply)\n",
    "multiplicacion_series = serie.multiply(otra_serie)\n",
    "\n",
    "print(\"Serie original:\\n\", serie)\n",
    "print(\"Multiplicación con escalar (operador *):\\n\", multiplicacion_escalar_op)\n",
    "print(\"Multiplicación entre Series (operador *):\\n\", multiplicacion_series_op)\n",
    "print(\"Multiplicación con escalar (multiply):\\n\", multiplicacion_escalar)\n",
    "print(\"Multiplicación entre Series (multiply):\\n\", multiplicacion_series)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **División (`/` o `divide`)**\n",
    "Divide los elementos de la Serie por un escalar o entre dos Series. Maneja divisiones por cero devolviendo `NaN`.\n",
    "\n",
    "**Definición:**  \n",
    "`serie / valor` o `serie.divide(valor)`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# División por un escalar (operador /)\n",
    "division_escalar_op = serie / 2\n",
    "\n",
    "# División entre Series (operador /)\n",
    "division_series_op = serie / otra_serie\n",
    "\n",
    "# División con un escalar (divide)\n",
    "division_escalar = serie.divide(2)\n",
    "\n",
    "# División entre Series (divide)\n",
    "division_series = serie.divide(otra_serie)\n",
    "\n",
    "print(\"Serie original:\\n\", serie)\n",
    "print(\"División con escalar (operador /):\\n\", division_escalar_op)\n",
    "print(\"División entre Series (operador /):\\n\", division_series_op)\n",
    "print(\"División con escalar (divide):\\n\", division_escalar)\n",
    "print(\"División entre Series (divide):\\n\", division_series)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **TABLA RESÚMEN:**\n",
    "\n",
    "| **Operación**         | **Método**                     | **Descripción**                                     |\n",
    "|-----------------------|-------------------------------|---------------------------------------------------|\n",
    "| Suma                 | `serie + valor` / `serie.add(valor)` | Suma cada elemento con el valor dado.             |\n",
    "| Resta                | `serie - valor` / `serie.subtract(valor)` | Resta cada elemento con el valor dado.           |\n",
    "| Multiplicación       | `serie * valor` / `serie.multiply(valor)` | Multiplica cada elemento por el valor dado.      |\n",
    "| División             | `serie / valor` / `serie.divide(valor)` | Divide cada elemento entre el valor dado.        |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Operaciones Relativas**\n",
    "\n",
    "#### **Potencias (`**` o `pow`)**\n",
    "Eleva cada elemento de la Serie a una potencia dada.\n",
    "\n",
    "**Definición:**  \n",
    "`serie ** valor` o `serie.pow(valor)`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Potencia con un escalar (operador **)\n",
    "potencia_escalar_op = serie ** 2\n",
    "\n",
    "# Potencia entre Series (operador **)\n",
    "potencia_series_op = serie ** otra_serie\n",
    "\n",
    "# Potencia con un escalar (pow)\n",
    "potencia_escalar = serie.pow(2)\n",
    "\n",
    "# Potencia entre Series (pow)\n",
    "potencia_series = serie.pow(otra_serie)\n",
    "\n",
    "print(\"Serie original:\\n\", serie)\n",
    "print(\"Potencia con escalar (operador **):\\n\", potencia_escalar_op)\n",
    "print(\"Potencia entre Series (operador **):\\n\", potencia_series_op)\n",
    "print(\"Potencia con escalar (pow):\\n\", potencia_escalar)\n",
    "print(\"Potencia entre Series (pow):\\n\", potencia_series)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Raíz Cuadrada (`sqrt`)**\n",
    "Calcula la raíz cuadrada de cada elemento en la Serie.\n",
    "\n",
    "**Definición:**  \n",
    "`np.sqrt(serie)`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Raíz cuadrada\n",
    "raices = np.sqrt(serie)\n",
    "\n",
    "print(\"Serie original:\\n\", serie)\n",
    "print(\"Raíz cuadrada de la Serie:\\n\", raices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Raíz Cúbica (`np.cbrt`)**\n",
    "\n",
    "Calcula la raíz cúbica de cada elemento de la Serie.\n",
    "\n",
    "**Definición:**  \n",
    "`np.cbrt(serie)`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular la raíz cúbica\n",
    "raiz_cubica = np.cbrt(serie)\n",
    "\n",
    "print(\"Serie original:\\n\", serie)\n",
    "print(\"Raíz cúbica de cada elemento:\\n\", raiz_cubica)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Exponencial (`np.exp`)**\n",
    "\n",
    "Calcula \\( e^x \\) para cada elemento de la Serie.\n",
    "\n",
    "**Definición:**  \n",
    "`np.exp(serie)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular el exponencial\n",
    "exponencial = np.exp(serie)\n",
    "\n",
    "print(\"Serie original:\\n\", serie)\n",
    "print(\"Exponencial (e^x) de cada elemento:\\n\", exponencial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Logaritmo Natural (`np.log`)**\n",
    "\n",
    "Calcula el logaritmo natural ln(x) de cada elemento. **Nota:** Solo se puede calcular para valores positivos.\n",
    "\n",
    "**Definición:**  \n",
    "`np.log(serie)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular el logaritmo natural (solo valores positivos)\n",
    "logaritmo_natural = np.log(serie[serie > 0])\n",
    "\n",
    "print(\"Serie original:\\n\", serie)\n",
    "print(\"Logaritmo natural de los valores positivos:\\n\", logaritmo_natural)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Logaritmo Base 10 (`np.log10`)**\n",
    "\n",
    "Calcula el logaritmo en base 10 de cada elemento. **Nota:** Solo se puede calcular para valores positivos.\n",
    "\n",
    "**Definición:**  \n",
    "`np.log10(serie)`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular el logaritmo base 10 (solo valores positivos)\n",
    "logaritmo_base_10 = np.log10(serie[serie > 0])\n",
    "\n",
    "print(\"Serie original:\\n\", serie)\n",
    "print(\"Logaritmo base 10 de los valores positivos:\\n\", logaritmo_base_10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Valor Absoluto (`np.abs` o `serie.abs()`)**\n",
    "\n",
    "Devuelve el valor absoluto de cada elemento de la Serie.\n",
    "\n",
    "**Definición:**  \n",
    "`np.abs(serie)` o `serie.abs()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular el valor absoluto\n",
    "valor_absoluto = np.abs(serie)\n",
    "\n",
    "print(\"Serie original:\\n\", serie)\n",
    "print(\"Valor absoluto de cada elemento:\\n\", valor_absoluto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Signo (`np.sign`)**\n",
    "\n",
    "Devuelve -1 para valores negativos, 1 para valores positivos y 0 para ceros.\n",
    "\n",
    "**Definición:**  \n",
    "`np.sign(serie)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular el signo de cada elemento\n",
    "signo = np.sign(serie)\n",
    "\n",
    "print(\"Serie original:\\n\", serie)\n",
    "print(\"Signo de cada elemento:\\n\", signo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **TABLA RESÚMEN:**\n",
    "\n",
    "| **Operación**         | **Método**                     | **Descripción**                                     |\n",
    "|-----------------------|-------------------------------|---------------------------------------------------|\n",
    "| Potencia             | `serie ** valor` / `serie.pow(valor)` | Eleva cada elemento de la Serie a una potencia.   |\n",
    "| Raíz Cuadrada        | `np.sqrt(serie)`               | Calcula la raíz cuadrada de cada elemento.         |\n",
    "| Raíz Cúbica             | `np.cbrt(serie)`                | Calcula la raíz cúbica de cada elemento.        |\n",
    "| Exponencial             | `np.exp(serie)`                 | Calcula \\( e^x \\) para cada elemento.           |\n",
    "| Logaritmo Natural       | `np.log(serie)`                 | Calcula \\( \\ln(x) \\) para cada elemento.        |\n",
    "| Logaritmo Base 10       | `np.log10(serie)`               | Calcula el logaritmo base 10 de cada elemento.  |\n",
    "| Valor Absoluto          | `np.abs(serie)` / `serie.abs()` | Devuelve el valor absoluto de cada elemento.    |\n",
    "| Signo                   | `np.sign(serie)`                | Devuelve -1, 0 o 1 según el signo del elemento. |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Redondeo o Truncamiento**\n",
    "\n",
    "#### **Redondeo (`round`)**\n",
    "Redondea los elementos de una Serie al número de decimales especificado.\n",
    "\n",
    "**Definición:**  \n",
    "`serie.round(decimales)`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Serie con decimales\n",
    "serie_decimales = pd.Series([1.234, 2.456, 3.678])\n",
    "\n",
    "# Redondear a 1 decimal\n",
    "redondeo = serie_decimales.round(1)\n",
    "\n",
    "print(\"Serie original:\\n\", serie_decimales)\n",
    "print(\"Serie redondeada:\\n\", redondeo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Truncamiento (`apply`)**\n",
    "Permite truncar los valores aplicando una función personalizada.\n",
    "\n",
    "**Definición:**  \n",
    "`serie.apply(funcion)`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Truncar los valores al entero más cercano hacia abajo\n",
    "truncado = serie_decimales.apply(lambda x: int(x))\n",
    "\n",
    "print(\"Serie original:\\n\", serie_decimales)\n",
    "print(\"Serie truncada:\\n\", truncado)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Ceil (`np.ceil`)**\n",
    "\n",
    "Redondea hacia arriba cada elemento de la Serie al entero más cercano.\n",
    "\n",
    "**Definición:**  \n",
    "`np.ceil(serie)`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redondear hacia arriba\n",
    "redondeo_arriba = np.ceil(serie_decimales)\n",
    "\n",
    "print(\"Serie original:\\n\", serie_decimales)\n",
    "print(\"Serie redondeada hacia arriba:\\n\", redondeo_arriba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Floor (`np.floor`)**\n",
    "\n",
    "Redondea hacia abajo cada elemento de la Serie al entero más cercano.\n",
    "\n",
    "**Definición:**  \n",
    "`np.floor(serie)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redondear hacia abajo\n",
    "redondeo_abajo = np.floor(serie_decimales)\n",
    "\n",
    "print(\"Serie original:\\n\", serie_decimales)\n",
    "print(\"Serie redondeada hacia abajo:\\n\", redondeo_abajo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Trunc (`np.trunc`)**\n",
    "\n",
    "Trunca los valores de una Serie eliminando su parte decimal.\n",
    "\n",
    "**Definición:**  \n",
    "`np.trunc(serie)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Truncar eliminando la parte decimal\n",
    "truncamiento = np.trunc(serie_decimales)\n",
    "\n",
    "print(\"Serie original:\\n\", serie_decimales)\n",
    "print(\"Serie truncada eliminando la parte decimal:\\n\", truncamiento)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **TABLA RESÚMEN:**\n",
    "\n",
    "| **Operación**       | **Método**                    | **Descripción**                                      |\n",
    "|---------------------|------------------------------|----------------------------------------------------|\n",
    "| Redondeo           | `serie.round(decimales)`      | Redondea cada elemento al número de decimales especificado. |\n",
    "| Truncamiento       | `serie.apply(funcion)`        | Aplica una función personalizada para truncar valores.      |\n",
    "| Redondeo Hacia Arriba | `np.ceil(serie)`            | Redondea cada elemento hacia arriba al entero más cercano.  |\n",
    "| Redondeo Hacia Abajo | `np.floor(serie)`            | Redondea cada elemento hacia abajo al entero más cercano.   |\n",
    "| Truncamiento (Decimales) | `np.trunc(serie)`        | Elimina la parte decimal de cada elemento.                  |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Conclusión**\n",
    "\n",
    "Las operaciones matemáticas en Pandas permiten trabajar de forma eficiente con datos numéricos. Entender cuándo usar operaciones básicas, relativas o de redondeo es clave para realizar análisis precisos.  \n",
    "- Usa métodos de Pandas para mantener índices y estructura.\n",
    "- Recurre a NumPy para cálculos avanzados o si los índices no son relevantes.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **1.3.2 Comparaciones y Filtrado**\n",
    "\n",
    "Las Series de Pandas permiten realizar comparaciones y generar máscaras booleanas que facilitan el filtrado de datos. Estas máscaras se aplican elemento a elemento, devolviendo `True` o `False` según la condición especificada.\n",
    "\n",
    "---\n",
    "\n",
    "### **¿Para qué usar comparaciones y filtrado?**\n",
    "1. **Comparaciones:** Identificar elementos que cumplan condiciones específicas.\n",
    "2. **Filtrado:** Extraer subconjuntos relevantes de datos basados en condiciones.\n",
    "\n",
    "---\n",
    "\n",
    "### **Principales Operaciones de Comparación**\n",
    "- **Igual a (`==`)**\n",
    "- **Diferente de (`!=`)**\n",
    "- **Mayor que (`>`)**\n",
    "- **Menor que (`<`)**\n",
    "- **Mayor o igual a (`>=`)**\n",
    "- **Menor o igual a (`<=`)**\n",
    "\n",
    "También puedes combinar múltiples condiciones usando:\n",
    "- **AND lógico (`&`)**\n",
    "- **OR lógico (`|`)**\n",
    "- **NOT lógico (`~`)**\n",
    "\n",
    "#### **Casos de Uso:**\n",
    "- **Series:** Para filtrar manteniendo los índices de los datos relevantes.\n",
    "- **NumPy:** Si necesitas aplicar condiciones más complejas o trabajar con arrays en paralelo.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Igualdad (`==`)**\n",
    "\n",
    "Devuelve `True` para los elementos que son iguales al valor especificado.\n",
    "\n",
    "**Definición:**  \n",
    "`serie == valor`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear una Serie de ejemplo\n",
    "serie = pd.Series([1, 2, 3, 4, 5])\n",
    "\n",
    "# Comparar con igualdad\n",
    "igual_a_3 = serie == 3\n",
    "\n",
    "print(\"Serie original:\\n\", serie)\n",
    "print(\"Máscara de igualdad con 3:\\n\", igual_a_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Operadores de Comparación**\n",
    "\n",
    "Las Series de Pandas permiten usar operadores de comparación para generar máscaras booleanas, incluyendo:\n",
    "\n",
    "- **Mayor que (`>`)**: Devuelve `True` para valores mayores.\n",
    "- **Menor que (`<`)**: Devuelve `True` para valores menores.\n",
    "- **Igual a (`==`)**: Devuelve `True` para valores iguales.\n",
    "- **Diferente de (`!=`)**: Devuelve `True` para valores distintos.\n",
    "- **Mayor o igual a (`>=`)**: Devuelve `True` para valores mayores o iguales.\n",
    "- **Menor o igual a (`<=`)**: Devuelve `True` para valores menores o iguales.\n",
    "\n",
    "**Definición:**  \n",
    "`serie operador valor`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear una Serie de ejemplo\n",
    "serie = pd.Series([10, 20, 30, 40, 50])\n",
    "\n",
    "# Comparaciones\n",
    "mayor_que = serie > 30\n",
    "menor_que = serie < 30\n",
    "igual_a = serie == 30\n",
    "diferente_de = serie != 30\n",
    "mayor_o_igual = serie >= 30\n",
    "menor_o_igual = serie <= 30\n",
    "\n",
    "# Filtrado usando máscaras booleanas\n",
    "filtrado = serie[mayor_que | menor_o_igual]\n",
    "\n",
    "print(\"Serie original:\\n\", serie)\n",
    "print(\"\\nMayor que 30:\\n\", mayor_que)\n",
    "print(\"Menor que 30:\\n\", menor_que)\n",
    "print(\"Igual a 30:\\n\", igual_a)\n",
    "print(\"Diferente de 30:\\n\", diferente_de)\n",
    "print(\"Mayor o igual a 30:\\n\", mayor_o_igual)\n",
    "print(\"Menor o igual a 30:\\n\", menor_o_igual)\n",
    "print(\"\\nFiltrado (mayor que 30 o menor o igual a 30):\\n\", filtrado)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **AND lógico (`&`)**\n",
    "\n",
    "Combina dos condiciones para devolver `True` solo si ambas son verdaderas.\n",
    "\n",
    "**Definición:**  \n",
    "`(serie > valor1) & (serie < valor2)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combinar condiciones con AND\n",
    "entre_2_y_4 = (serie > 2) & (serie < 4)\n",
    "\n",
    "print(\"Serie original:\\n\", serie)\n",
    "print(\"Máscara para valores entre 2 y 4:\\n\", entre_2_y_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **OR lógico (`|`)**\n",
    "\n",
    "Combina dos condiciones para devolver `True` si al menos una es verdadera.\n",
    "\n",
    "**Definición:**  \n",
    "`(serie < valor1) | (serie > valor2)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combinar condiciones con OR\n",
    "menor_a_2_o_mayor_a_4 = (serie < 2) | (serie > 4)\n",
    "\n",
    "print(\"Serie original:\\n\", serie)\n",
    "print(\"Máscara para valores menores a 2 o mayores a 4:\\n\", menor_a_2_o_mayor_a_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **NOT lógico (`~`)**\n",
    "\n",
    "Invierte una condición booleana. Devuelve `True` donde la condición original es `False`.\n",
    "\n",
    "**Definición:**  \n",
    "`~condicion`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Invertir la condición \"mayor a 3\"\n",
    "no_mayores_a_3 = ~mayor_a_3\n",
    "\n",
    "print(\"Serie original:\\n\", serie)\n",
    "print(\"Valores NO mayores a 3:\\n\", serie[no_mayores_a_3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Máscaras Booleanas en Series**\n",
    "\n",
    "En Pandas, las **máscaras booleanas** son esenciales para trabajar con datos de forma selectiva. Aplicadas a Series, permiten:\n",
    "1. **Filtrar valores:** Extraer elementos que cumplen ciertas condiciones.\n",
    "2. **Identificar patrones:** Detectar valores específicos o rangos.\n",
    "3. **Aplicar modificaciones:** Cambiar elementos específicos de forma eficiente.\n",
    "\n",
    "---\n",
    "\n",
    "### **1. Crear Máscaras Booleanas**\n",
    "\n",
    "Las máscaras booleanas son Series de valores `True` o `False` generadas a partir de una condición.\n",
    "\n",
    "**Definición:**  \n",
    "`serie[condicion]`\n",
    "\n",
    "#### **Ejemplo: Máscara Booleana con Condición Simple**\n",
    "\n",
    "Filtrar los valores mayores a un umbral específico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear una Serie de ejemplo\n",
    "serie = pd.Series([10, 20, 30, 40, 50])\n",
    "\n",
    "# Máscara booleana: valores mayores a 30\n",
    "mayores_a_30 = serie > 30\n",
    "\n",
    "# Filtrar usando la máscara\n",
    "filtrado = serie[mayores_a_30]\n",
    "\n",
    "print(\"Serie original:\\n\", serie)\n",
    "print(\"\\nMáscara booleana (valores > 30):\\n\", mayores_a_30)\n",
    "print(\"\\nValores filtrados:\\n\", filtrado)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2. Máscaras Booleanas Combinadas**\n",
    "\n",
    "Las máscaras pueden combinarse usando operadores lógicos:\n",
    "- **AND (`&`)**\n",
    "- **OR (`|`)**\n",
    "- **NOT (`~`)**\n",
    "\n",
    "Esto permite construir filtros más complejos.\n",
    "\n",
    "#### **Ejemplo: Combinar Condiciones**\n",
    "\n",
    "Filtrar valores que están en un rango específico o fuera de otro.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combinar condiciones: valores entre 20 y 40\n",
    "entre_20_y_40 = (serie > 20) & (serie < 40)\n",
    "\n",
    "# Combinar condiciones: valores menores a 20 o mayores a 40\n",
    "menor_a_20_o_mayor_a_40 = (serie < 20) | (serie > 40)\n",
    "\n",
    "print(\"Valores entre 20 y 40:\\n\", serie[entre_20_y_40])\n",
    "print(\"\\nValores menores a 20 o mayores a 40:\\n\", serie[menor_a_20_o_mayor_a_40])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3. Modificar Valores con Máscaras Booleanas**\n",
    "\n",
    "Puedes usar máscaras booleanas para cambiar valores específicos en una Serie.\n",
    "\n",
    "#### **Ejemplo: Modificar Valores Selectivamente**\n",
    "\n",
    "Incrementar ciertos valores basados en una condición.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Incrementar valores mayores a 30 en un 10%\n",
    "serie[serie > 30] *= 1.10\n",
    "\n",
    "print(\"Serie después de modificar valores mayores a 30:\\n\", serie)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4. Invertir Máscaras con `~`**\n",
    "\n",
    "El operador `~` invierte una máscara booleana, cambiando `True` a `False` y viceversa.\n",
    "\n",
    "#### **Ejemplo: Invertir una Condición**\n",
    "\n",
    "Filtrar los valores que NO cumplen una condición."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Invertir la máscara para obtener valores menores o iguales a 30\n",
    "no_mayores_a_30 = ~mayores_a_30\n",
    "\n",
    "print(\"Valores que NO son mayores a 30:\\n\", serie[no_mayores_a_30])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Conclusión**\n",
    "\n",
    "- Las máscaras booleanas son clave para realizar análisis y manipulaciones rápidas en Series.\n",
    "- Combinando condiciones con operadores lógicos (`&`, `|`, `~`) puedes construir filtros avanzados.\n",
    "- Su flexibilidad permite no solo filtrar, sino también modificar valores de forma eficiente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1.3.3. Operaciones de Agregación**\n",
    "\n",
    "Las Series ofrecen métodos para calcular valores agregados como suma, promedio, y más. Estos cálculos preservan la semántica de Pandas.\n",
    "\n",
    "#### **Casos de Uso:**\n",
    "- **Series:** Cuando necesitas trabajar con datos etiquetados y mantener metadatos como los índices.\n",
    "- **NumPy:** Para operaciones más rápidas en grandes volúmenes de datos, sin preocuparte por los índices.\n",
    "\n",
    "Las operaciones de agregación permiten obtener valores resumidos a partir de los datos en una Serie. Estas operaciones son útiles para:\n",
    "1. **Obtener estadísticas básicas:** Suma, promedio, máximo, mínimo, etc.\n",
    "2. **Evaluar la distribución:** Calcular varianza, desviación estándar, etc.\n",
    "\n",
    "En Pandas, estas operaciones son métodos que se aplican directamente sobre las Series.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Suma de los Valores (`sum`)**\n",
    "\n",
    "Calcula la suma de todos los elementos de la Serie.\n",
    "\n",
    "**Definición:**  \n",
    "`serie.sum()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular la suma\n",
    "suma = serie.sum()\n",
    "\n",
    "print(\"Suma de los valores:\", suma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Promedio de los Valores (`mean`)**\n",
    "\n",
    "Calcula el promedio (media aritmética) de los valores de la Serie.\n",
    "\n",
    "**Definición:**  \n",
    "`serie.mean()`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular el promedio\n",
    "promedio = serie.mean()\n",
    "\n",
    "print(\"Promedio de los valores:\", promedio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Valor Máximo (`max`)**\n",
    "\n",
    "Devuelve el valor máximo de la Serie.\n",
    "\n",
    "**Definición:**  \n",
    "`serie.max()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular el máximo\n",
    "maximo = serie.max()\n",
    "\n",
    "print(\"Valor máximo:\", maximo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Valor Mínimo (`min`)**\n",
    "\n",
    "Devuelve el valor mínimo de la Serie.\n",
    "\n",
    "**Definición:**  \n",
    "`serie.min()`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular el mínimo\n",
    "minimo = serie.min()\n",
    "\n",
    "print(\"Valor mínimo:\", minimo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Desviación Estándar (`std`)**\n",
    "\n",
    "Calcula la desviación estándar de los valores de la Serie, que mide la dispersión de los datos.\n",
    "\n",
    "**Definición:**  \n",
    "`serie.std()`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular la desviación estándar\n",
    "desviacion = serie.std()\n",
    "\n",
    "print(\"Desviación estándar:\", desviacion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Varianza (`var`)**\n",
    "\n",
    "Calcula la varianza de los valores de la Serie, que es el cuadrado de la desviación estándar.\n",
    "\n",
    "**Definición:**  \n",
    "`serie.var()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular la varianza\n",
    "varianza = serie.var()\n",
    "\n",
    "print(\"Varianza:\", varianza)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Conteo de Elementos No Nulos (`count`)**\n",
    "\n",
    "Devuelve el número de elementos no nulos en la Serie.\n",
    "\n",
    "**Definición:**  \n",
    "`serie.count()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contar los elementos no nulos\n",
    "conteo = serie.count()\n",
    "\n",
    "print(\"Número de elementos no nulos:\", conteo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Mediana (`median`)**\n",
    "\n",
    "Calcula la mediana (valor central) de los valores en la Serie.\n",
    "\n",
    "**Definición:**  \n",
    "`serie.median()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular la mediana\n",
    "mediana = serie.median()\n",
    "\n",
    "print(\"Mediana:\", mediana)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Tabla Resumen:**\n",
    "\n",
    "| **Operación**       | **Método**       | **Descripción**                                       |\n",
    "|---------------------|------------------|-----------------------------------------------------|\n",
    "| Suma               | `serie.sum()`    | Calcula la suma de todos los elementos de la Serie. |\n",
    "| Promedio           | `serie.mean()`   | Calcula la media aritmética de los elementos.       |\n",
    "| Máximo             | `serie.max()`    | Devuelve el valor máximo de la Serie.              |\n",
    "| Mínimo             | `serie.min()`    | Devuelve el valor mínimo de la Serie.              |\n",
    "| Desviación Estándar| `serie.std()`    | Calcula la dispersión de los datos.                |\n",
    "| Varianza           | `serie.var()`    | Calcula la variabilidad de los datos.              |\n",
    "| Conteo             | `serie.count()`  | Cuenta los elementos no nulos en la Serie.         |\n",
    "| Mediana            | `serie.median()` | Devuelve el valor central de los elementos.        |\n",
    "\n",
    "\n",
    "### **Conclusión**\n",
    "\n",
    "Las operaciones de agregación en Series de Pandas son similares a las de NumPy, pero ofrecen una integración perfecta con las estructuras de Pandas, como los índices, para un análisis más detallado y eficiente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1.3.4. Métodos Específicos de Pandas**\n",
    "\n",
    "Pandas incluye métodos únicos para Series que no están disponibles en NumPy. Estos métodos son útiles para análisis rápidos o para explorar datos categóricos.\n",
    "\n",
    "---\n",
    "\n",
    "### **Métodos Específicos Incluidos**\n",
    "1. `value_counts()`\n",
    "2. `unique()`\n",
    "3. `rank()`\n",
    "4. `nunique()`\n",
    "5. `isnull()` y `notnull()`\n",
    "6. `replace()`\n",
    "7. `clip()`\n",
    "\n",
    "#### **Casos de Uso:**\n",
    "Siempre que necesites información adicional sobre las frecuencias, unicidad o rangos en una Serie, estos métodos son esenciales.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Frecuencia de Valores (`value_counts`)**\n",
    "\n",
    "Devuelve una Serie que muestra la frecuencia de cada valor único en la Serie original.\n",
    "\n",
    "**Definición:**  \n",
    "`serie.value_counts(normalize=False, sort=True)`\n",
    "\n",
    "- **`normalize`**: Si es `True`, devuelve proporciones en lugar de conteos.\n",
    "- **`sort`**: Si es `True`, ordena los valores por frecuencia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear una Serie de ejemplo\n",
    "serie = pd.Series(['A', 'B', 'A', 'C', 'B', 'A'])\n",
    "\n",
    "# Contar la frecuencia de cada valor\n",
    "frecuencia = serie.value_counts()\n",
    "\n",
    "print(\"Frecuencia de cada valor:\\n\", frecuencia)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Valores Únicos (`unique`)**\n",
    "\n",
    "Devuelve un array de NumPy con los valores únicos de la Serie.\n",
    "\n",
    "**Definición:**  \n",
    "`serie.unique()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener los valores únicos\n",
    "valores_unicos = serie.unique()\n",
    "\n",
    "print(\"Valores únicos en la Serie:\\n\", valores_unicos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Rango de Valores (`rank`)**\n",
    "\n",
    "Asigna un rango a cada elemento basado en su orden en la Serie. \n",
    "\n",
    "**Definición:**  \n",
    "`serie.rank(method='average', ascending=True)`\n",
    "\n",
    "- **`method`**: Cómo manejar empates (`average`, `min`, `max`, `first`, `dense`).\n",
    "- **`ascending`**: Si es `True`, ordena en orden ascendente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear una Serie de ejemplo con valores repetidos\n",
    "serie_rango = pd.Series([100, 200, 200, 300])\n",
    "\n",
    "# Calcular los rangos\n",
    "rango = serie_rango.rank()\n",
    "\n",
    "print(\"Serie original:\\n\", serie_rango)\n",
    "print(\"Rangos asignados:\\n\", rango)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Número de Valores Únicos (`nunique`)**\n",
    "\n",
    "Devuelve el número de valores únicos en la Serie.\n",
    "\n",
    "**Definición:**  \n",
    "`serie.nunique()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular el número de valores únicos\n",
    "numero_unicos = serie.nunique()\n",
    "\n",
    "print(\"Número de valores únicos:\", numero_unicos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Identificar Valores Nulos (`isnull` y `notnull`)**\n",
    "\n",
    "- **`isnull`**: Devuelve una máscara booleana indicando dónde hay valores nulos.\n",
    "- **`notnull`**: Devuelve una máscara booleana indicando dónde NO hay valores nulos.\n",
    "\n",
    "**Definición:**  \n",
    "`serie.isnull()`  \n",
    "`serie.notnull()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear una Serie con valores nulos\n",
    "serie_nulos = pd.Series([1, None, 2, None, 3])\n",
    "\n",
    "# Identificar valores nulos\n",
    "nulos = serie_nulos.isnull()\n",
    "\n",
    "# Identificar valores no nulos\n",
    "no_nulos = serie_nulos.notnull()\n",
    "\n",
    "print(\"Valores nulos:\\n\", nulos)\n",
    "print(\"Valores no nulos:\\n\", no_nulos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Reemplazar Valores (`replace`)**\n",
    "\n",
    "Reemplaza valores específicos en la Serie por otros valores.\n",
    "\n",
    "**Definición:**  \n",
    "`serie.replace(to_replace, value)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reemplazar valores específicos\n",
    "serie_reemplazada = serie.replace('A', 'Z')\n",
    "\n",
    "print(\"Serie original:\\n\", serie)\n",
    "print(\"Serie después de reemplazar 'A' por 'Z':\\n\", serie_reemplazada)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Limitar Valores (`clip`)**\n",
    "\n",
    "Limita los valores de la Serie a un rango especificado.\n",
    "\n",
    "**Definición:**  \n",
    "`serie.clip(lower, upper)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear una Serie numérica\n",
    "serie_numerica = pd.Series([1, 2, 3, 4, 5])\n",
    "\n",
    "# Limitar valores entre 2 y 4\n",
    "serie_clipeada = serie_numerica.clip(2, 4)\n",
    "\n",
    "print(\"Serie original:\\n\", serie_numerica)\n",
    "print(\"Serie después de limitar valores entre 2 y 4:\\n\", serie_clipeada)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Tabla Resumen:**\n",
    "\n",
    "| **Método**        | **Descripción**                                                                 |\n",
    "|--------------------|---------------------------------------------------------------------------------|\n",
    "| `value_counts()`  | Devuelve la frecuencia de cada valor único en la Serie.                        |\n",
    "| `unique()`        | Devuelve un array con los valores únicos en la Serie.                          |\n",
    "| `rank()`          | Asigna un rango a cada elemento basado en su orden en la Serie.                |\n",
    "| `nunique()`       | Devuelve el número de valores únicos en la Serie.                              |\n",
    "| `isnull()`        | Devuelve una máscara booleana indicando dónde hay valores nulos.               |\n",
    "| `notnull()`       | Devuelve una máscara booleana indicando dónde NO hay valores nulos.            |\n",
    "| `replace()`       | Reemplaza valores específicos en la Serie por otros valores.                   |\n",
    "| `clip()`          | Limita los valores de la Serie a un rango especificado.                        |\n",
    "\n",
    "\n",
    "### **Conclusión**\n",
    "\n",
    "Los métodos específicos de Pandas para Series son herramientas poderosas que permiten:\n",
    "1. Analizar datos categóricos (`value_counts`, `unique`, `nunique`).\n",
    "2. Transformar y ajustar datos (`replace`, `clip`).\n",
    "3. Trabajar con datos nulos (`isnull`, `notnull`).\n",
    "4. Calcular rangos y estadísticas personalizadas (`rank`).\n",
    "\n",
    "Estos métodos ofrecen capacidades avanzadas que no están disponibles en bibliotecas como NumPy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Conclusión General**\n",
    "\n",
    "- Usa **métodos de Pandas** cuando necesites trabajar con datos indexados o quieras aprovechar funciones específicas como `value_counts()`.\n",
    "- Usa **NumPy** cuando la eficiencia o las operaciones matemáticas avanzadas sean más importantes que los índices.\n",
    "\n",
    "Las operaciones básicas con Series son esenciales para manipular y analizar datos de manera eficiente en Pandas.\n",
    "\n",
    "Las Series son la base de muchas operaciones en Pandas. Representan una forma poderosa de trabajar con datos unidimensionales, combinando la flexibilidad de los índices con las capacidades matemáticas de los arrays.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **2. DataFrames en Pandas**\n",
    "\n",
    "Un **DataFrame** es la estructura de datos principal en Pandas. Es una tabla bidimensional etiquetada con filas e índices, que combina múltiples Series. Es ideal para manejar datos tabulares como:\n",
    "- Hojas de cálculo.\n",
    "- Tablas SQL.\n",
    "- Datasets de análisis de datos.\n",
    "\n",
    "---\n",
    "\n",
    "### **Características Clave de los DataFrames**\n",
    "1. **Columnas y Filas:** Cada columna es una `Serie`, y cada fila está etiquetada con un índice.\n",
    "2. **Tipos de Datos Mixtos:** Permite diferentes tipos de datos en las columnas.\n",
    "3. **Operaciones Flexibles:** Facilita el filtrado, agrupación, unión y agregación de datos.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2.1. Creación de DataFrames**\n",
    "\n",
    "Un **DataFrame** es una tabla bidimensional en Pandas, con filas e índices etiquetados. Es la estructura principal de la biblioteca y permite trabajar con datos tabulares de forma eficiente.\n",
    "\n",
    "---\n",
    "\n",
    "### **¿Qué es un DataFrame?**\n",
    "\n",
    "Un DataFrame combina:\n",
    "1. **Filas etiquetadas:** Representan instancias de datos (índices).\n",
    "2. **Columnas etiquetadas:** Cada columna es una Serie y representa una variable o atributo.\n",
    "3. **Datos heterogéneos:** Permite mezclar tipos de datos (números, cadenas, booleanos, etc.).\n",
    "\n",
    "---\n",
    "\n",
    "### **Características Clave**\n",
    "- **Flexibilidad:** Soporta operaciones complejas como filtrado, agrupación y combinaciones.\n",
    "- **Compatibilidad:** Fácil integración con archivos de datos (CSV, JSON, Excel, etc.).\n",
    "- **Optimización:** Diseñado para manejar grandes volúmenes de datos eficientemente.\n",
    "\n",
    "---\n",
    "\n",
    "### **Métodos de Creación**\n",
    "\n",
    "Los DataFrames se pueden crear de diversas formas en Pandas. A continuación, exploramos los métodos más comunes.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1. Desde Diccionarios**\n",
    "\n",
    "Un diccionario convierte sus claves en nombres de las columnas y los valores en los datos correspondientes.\n",
    "\n",
    "**Definición:**  \n",
    "`pd.DataFrame(data)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un DataFrame desde un diccionario\n",
    "data = {\n",
    "    'Nombre': ['Juan', 'Ana', 'Luis'],\n",
    "    'Edad': [25, 32, 19],\n",
    "    'Salario': [3000, 4000, 1500]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(\"DataFrame creado desde un diccionario:\\n\", df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2. Desde Listas o Listas Anidadas**\n",
    "\n",
    "Cada lista interna se convierte en una fila del DataFrame.\n",
    "\n",
    "**Definición:**  \n",
    "`pd.DataFrame(data, columns=[nombres_columnas])`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un DataFrame desde listas anidadas\n",
    "data = [\n",
    "    [1, 'Juan', 3000],\n",
    "    [2, 'Ana', 4000],\n",
    "    [3, 'Luis', 1500]\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(data, columns=['ID', 'Nombre', 'Salario'])\n",
    "\n",
    "print(\"DataFrame creado desde listas anidadas:\\n\", df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3. Desde Matrices de NumPy**\n",
    "\n",
    "Las matrices se convierten en el contenido del DataFrame, y puedes etiquetar columnas e índices opcionalmente.\n",
    "\n",
    "**Definición:**  \n",
    "`pd.DataFrame(data, index=[nombres_filas], columns=[nombres_columnas])`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear una matriz de NumPy\n",
    "matriz = np.array([\n",
    "    [1, 25, 3000],\n",
    "    [2, 32, 4000],\n",
    "    [3, 19, 1500]\n",
    "])\n",
    "\n",
    "# Convertir la matriz en un DataFrame\n",
    "df = pd.DataFrame(matriz, columns=['ID', 'Edad', 'Salario'])\n",
    "\n",
    "print(\"DataFrame creado desde una matriz de NumPy:\\n\", df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4. Desde Archivos**\n",
    "\n",
    "Puedes importar datos desde archivos como CSV, Excel o JSON.\n",
    "\n",
    "**Definición:**  \n",
    "`pd.read_csv(filepath)`  \n",
    "`pd.read_excel(filepath)`  \n",
    "`pd.read_json(filepath)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar un DataFrame desde un archivo CSV\n",
    "# Nota: Proporciona la ruta al archivo en tu sistema para ejecutar esto.\n",
    "\n",
    "# ruta = \"ruta/al/archivo.csv\"\n",
    "# df = pd.read_csv(ruta)\n",
    "\n",
    "# print(\"DataFrame importado desde un archivo CSV:\\n\", df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Tabla Resumen: Métodos de Creación de DataFrames**\n",
    "\n",
    "| **Método**            | **Definición**                           | **Descripción**                                           |\n",
    "|------------------------|-------------------------------------------|-----------------------------------------------------------|\n",
    "| Desde Diccionarios     | `pd.DataFrame(data)`                     | Convierte claves en nombres de columnas y valores en datos.|\n",
    "| Desde Listas           | `pd.DataFrame(data, columns=[])`         | Cada lista interna representa una fila del DataFrame.      |\n",
    "| Desde Matrices de NumPy| `pd.DataFrame(data, columns=[], index=[])`| Convierte la matriz en un DataFrame con columnas e índices opcionales.|\n",
    "| Desde Archivos         | `pd.read_csv(filepath)`                  | Importa datos desde archivos como CSV, Excel o JSON.       |\n",
    "\n",
    "### **Conclusión**\n",
    "\n",
    "Los DataFrames son la estructura principal de Pandas para manejar datos tabulares. Su flexibilidad permite crearlos desde múltiples fuentes:\n",
    "- Diccionarios para datos estructurados.\n",
    "- Listas o matrices de NumPy para datos organizados.\n",
    "- Archivos como CSV, JSON o Excel para datos externos.\n",
    "\n",
    "Entender cómo crearlos es el primer paso para manipular y analizar datos de manera eficiente.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **2.2. Acceso y Selección de Datos**\n",
    "\n",
    "Una de las características más importantes de los DataFrames en Pandas es la facilidad para acceder, seleccionar y modificar datos. Estas operaciones son esenciales para el análisis y manipulación de datos, ya que permiten extraer subconjuntos relevantes, aplicar transformaciones específicas y realizar análisis detallados.\n",
    "\n",
    "### **¿Por qué es importante?**\n",
    "1. **Filtrar Información Relevante:** Extraer datos específicos para análisis focalizados.\n",
    "2. **Modificar y Actualizar Datos:** Realizar ajustes en valores o estructuras según sea necesario.\n",
    "3. **Flexibilidad:** Permite trabajar con datos tanto a nivel de filas como de columnas, manteniendo la semántica y estructura del DataFrame.\n",
    "\n",
    "### **¿Qué aprenderás en esta sección?**\n",
    "- Métodos básicos y avanzados para acceder a datos.\n",
    "- Uso de slicing y máscaras booleanas para filtrar subconjuntos.\n",
    "- Modificación de valores en filas, columnas o subconjuntos.\n",
    "\n",
    "Este módulo te guiará desde las operaciones más simples hasta técnicas avanzadas para que tengas control total sobre los datos en tus DataFrames.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2.2.1. Acceso Básico a Filas y Columnas**\n",
    "\n",
    "El acceso básico a los datos en un DataFrame de Pandas se realiza principalmente usando corchetes `[]`. Este enfoque es directo y sencillo, pero tiene ciertas limitaciones en comparación con los métodos avanzados como `.loc` y `.iloc`.\n",
    "\n",
    "---\n",
    "\n",
    "### **Acceso a Columnas usando `[]`**\n",
    "\n",
    "En Pandas, los nombres de las columnas se utilizan como claves para acceder a sus datos. Esto es similar a cómo funcionan los diccionarios en Python.\n",
    "\n",
    "**Definición:**  \n",
    "`dataframe['nombre_columna']`\n",
    "\n",
    "- Devuelve una `Serie` con los datos de la columna especificada.\n",
    "- Si se pasan varios nombres de columna en una lista, se devuelve un nuevo DataFrame.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un DataFrame de ejemplo\n",
    "data = {'Nombre': ['Juan', 'Ana', 'Luis'], 'Edad': [25, 32, 19], 'Salario': [3000, 4000, 1500]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Acceso a una columna\n",
    "columna_edad = df['Edad']\n",
    "\n",
    "# Acceso a varias columnas\n",
    "columnas_seleccionadas = df[['Nombre', 'Salario']]\n",
    "\n",
    "print(\"Columna 'Edad':\\n\", columna_edad)\n",
    "print(\"\\nColumnas 'Nombre' y 'Salario':\\n\", columnas_seleccionadas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Acceso a Filas por Índices Numéricos**\n",
    "\n",
    "Para acceder a filas individuales o subconjuntos por sus índices numéricos, se utiliza slicing básico. Esto es similar a cómo se manejan las listas en Python.\n",
    "\n",
    "**Definición:**  \n",
    "`dataframe[inicio:fin]`\n",
    "\n",
    "- **Inicio:** Índice inicial (incluido).\n",
    "- **Fin:** Índice final (excluido).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acceso a una sola fila por índice numérico\n",
    "fila_unica = df[1:2]  # Devuelve la fila 1\n",
    "\n",
    "# Acceso a un rango de filas\n",
    "rango_filas = df[0:2]  # Devuelve las filas 0 y 1\n",
    "\n",
    "print(\"Fila única (índice 1):\\n\", fila_unica)\n",
    "print(\"\\nRango de filas (índices 0 a 2, excluyendo el 2):\\n\", rango_filas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Conclusión**\n",
    "\n",
    "El acceso básico con `[]` es una herramienta sencilla y rápida para trabajar con columnas o filas en un DataFrame. Sin embargo, para operaciones más avanzadas o específicas, se recomienda usar métodos como `.loc` o `.iloc`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  **2.2.2. Acceso Avanzado con `.loc` y `.iloc`**\n",
    "\n",
    "Los métodos `.loc` y `.iloc` permiten acceder a datos en un DataFrame de manera más avanzada, precisa y flexible. A diferencia del acceso básico con `[]`, estos métodos ofrecen soporte completo para:\n",
    "- Selección de filas y columnas simultáneamente.\n",
    "- Uso de índices y etiquetas personalizadas.\n",
    "- Operaciones más complejas como condiciones y máscaras booleanas.\n",
    "\n",
    "---\n",
    "\n",
    "### **Uso de `.loc` para Acceder por Etiquetas**\n",
    "\n",
    "El método `.loc` selecciona datos basándose en etiquetas de índices o nombres de columnas. Es útil cuando los índices tienen significado o los nombres de las columnas son importantes.\n",
    "\n",
    "**Definición:**  \n",
    "`dataframe.loc[fila, columna]`\n",
    "\n",
    "- **Fila:** Nombre o etiqueta del índice.\n",
    "- **Columna:** Nombre de la columna.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un DataFrame de ejemplo\n",
    "data = {'Nombre': ['Juan', 'Ana', 'Luis'], 'Edad': [25, 32, 19], 'Salario': [3000, 4000, 1500]}\n",
    "df = pd.DataFrame(data, index=['a', 'b', 'c'])\n",
    "\n",
    "# Seleccionar una fila por etiqueta\n",
    "fila_a = df.loc['a']\n",
    "\n",
    "# Seleccionar un elemento específico\n",
    "elemento = df.loc['b', 'Salario']\n",
    "\n",
    "# Seleccionar múltiples filas y columnas\n",
    "subconjunto = df.loc[['a', 'b'], ['Nombre', 'Edad']]\n",
    "\n",
    "print(\"Fila 'a':\\n\", fila_a)\n",
    "print(\"\\nElemento en fila 'b', columna 'Salario':\", elemento)\n",
    "print(\"\\nSubconjunto de filas y columnas:\\n\", subconjunto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Uso de `.iloc` para Acceder por Posiciones**\n",
    "\n",
    "El método `.iloc` selecciona datos basándose en posiciones numéricas. Es útil para acceso por índices enteros, sin importar sus etiquetas.\n",
    "\n",
    "**Definición:**  \n",
    "`dataframe.iloc[fila, columna]`\n",
    "\n",
    "- **Fila:** Posición numérica del índice.\n",
    "- **Columna:** Posición numérica de la columna.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionar una fila por posición numérica\n",
    "fila_0 = df.iloc[0]\n",
    "\n",
    "# Seleccionar un elemento específico\n",
    "elemento = df.iloc[1, 2]\n",
    "\n",
    "# Seleccionar múltiples filas y columnas\n",
    "subconjunto = df.iloc[0:2, 0:2]\n",
    "\n",
    "print(\"Fila 0:\\n\", fila_0)\n",
    "print(\"\\nElemento en fila 1, columna 2:\", elemento)\n",
    "print(\"\\nSubconjunto de filas y columnas:\\n\", subconjunto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Comparativa entre `.loc` y `.iloc`**\n",
    "\n",
    "- **`.loc`:** Accede a los datos basándose en etiquetas de índice y nombres de columnas.\n",
    "- **`.iloc`:** Accede a los datos basándose en posiciones numéricas.\n",
    "- **Uso Combinado:** Ambos pueden utilizarse según sea necesario, dependiendo del tipo de acceso requerido.\n",
    "\n",
    "**Tabla Comparativa:**\n",
    "\n",
    "| **Método** | **Acceso**                | **Ejemplo**              |\n",
    "|------------|---------------------------|--------------------------|\n",
    "| `.loc`     | Por etiquetas.            | `df.loc['a', 'Salario']` |\n",
    "| `.iloc`    | Por posiciones numéricas. | `df.iloc[0, 2]`          |\n",
    "\n",
    "### **Conclusión**\n",
    "\n",
    "Los métodos `.loc` y `.iloc` ofrecen una forma poderosa y precisa de acceder a los datos en un DataFrame. Su flexibilidad permite seleccionar filas, columnas o elementos específicos, ya sea por etiquetas o posiciones numéricas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2.2.4. Filtrado Condicional**\n",
    "\n",
    "El filtrado condicional en Pandas permite seleccionar subconjuntos de datos basados en condiciones específicas. Esto se logra mediante máscaras booleanas, que son arrays de valores `True` o `False` aplicados al DataFrame.\n",
    "\n",
    "---\n",
    "\n",
    "### **¿Qué es una Máscara Booleana?**\n",
    "\n",
    "Una máscara booleana es una Serie o DataFrame de valores `True` y `False`, que se genera evaluando una condición sobre los datos. Se utiliza para:\n",
    "1. **Filtrar Filas:** Seleccionar solo las filas que cumplen ciertas condiciones.\n",
    "2. **Filtrar Columnas:** Aplicar condiciones a columnas específicas.\n",
    "\n",
    "**Definición:**  \n",
    "`dataframe[condicion]`\n",
    "\n",
    "---\n",
    "\n",
    "### **Uso de Máscaras Booleanas para Filtrar Filas**\n",
    "\n",
    "Puedes aplicar una condición a una columna para generar una máscara booleana y usarla para filtrar filas.\n",
    "\n",
    "**Ejemplo Básico:**  \n",
    "Filtrar filas donde los valores en una columna sean mayores a un umbral.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un DataFrame de ejemplo\n",
    "data = {'Nombre': ['Juan', 'Ana', 'Luis', 'María'], 'Edad': [25, 32, 19, 45], 'Salario': [3000, 4000, 1500, 5000]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Máscara booleana para filtrar filas con edad > 30\n",
    "filtro_edad = df['Edad'] > 30\n",
    "resultado = df[filtro_edad]\n",
    "\n",
    "print(\"Máscara booleana (Edad > 30):\\n\", filtro_edad)\n",
    "print(\"\\nFiltrado (Edad > 30):\\n\", resultado)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Filtrado con Condiciones Múltiples**\n",
    "\n",
    "Las máscaras booleanas pueden combinarse usando operadores lógicos para crear filtros más complejos:\n",
    "- **AND (`&`)**: Devuelve `True` si ambas condiciones son verdaderas.\n",
    "- **OR (`|`)**: Devuelve `True` si al menos una condición es verdadera.\n",
    "- **NOT (`~`)**: Invierte una condición (de `True` a `False` y viceversa).\n",
    "\n",
    "**Ejemplo: Filtrar empleados con edad > 20 y salario > 3000.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar con múltiples condiciones (AND lógico)\n",
    "filtro_combinado = (df['Edad'] > 20) & (df['Salario'] > 3000)\n",
    "resultado_combinado = df[filtro_combinado]\n",
    "\n",
    "print(\"Filtrado (Edad > 20 y Salario > 3000):\\n\", resultado_combinado)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Filtrado con Condiciones sobre Columnas**\n",
    "\n",
    "Además de las filas, puedes aplicar condiciones específicas a las columnas del DataFrame.\n",
    "\n",
    "**Ejemplo:** Filtrar filas basándose en valores en múltiples columnas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar filas donde el salario sea mayor que la edad multiplicada por 100\n",
    "filtro_columnas = df['Salario'] > (df['Edad'] * 100)\n",
    "resultado_columnas = df[filtro_columnas]\n",
    "\n",
    "print(\"Filtrado (Salario > Edad * 100):\\n\", resultado_columnas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Filtrado Inverso con `~`**\n",
    "\n",
    "El operador `~` invierte una condición booleana, seleccionando los elementos que **NO** cumplen con la condición.\n",
    "\n",
    "**Ejemplo:** Filtrar empleados cuya edad NO sea mayor a 30."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar empleados cuya edad NO sea mayor a 30\n",
    "filtro_inverso = ~(df['Edad'] > 30)\n",
    "resultado_inverso = df[filtro_inverso]\n",
    "\n",
    "print(\"Filtrado (Edad NO > 30):\\n\", resultado_inverso)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Conclusión**\n",
    "\n",
    "El filtrado condicional en Pandas es una herramienta poderosa que permite extraer subconjuntos de datos con gran precisión. Combinar máscaras booleanas con operadores lógicos ofrece flexibilidad para construir filtros avanzados y trabajar eficientemente con grandes volúmenes de datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2.2.5. Modificación de Valores**\n",
    "\n",
    "Pandas permite modificar valores en un DataFrame de manera directa, ya sea en filas, columnas o subconjuntos específicos. Esta funcionalidad es esencial para actualizar datos, realizar correcciones o ajustar valores según condiciones.\n",
    "\n",
    "---\n",
    "\n",
    "### **Modificación de Valores en Filas Específicas**\n",
    "\n",
    "Puedes modificar valores en filas específicas utilizando los índices de las filas. Esto se hace accediendo directamente a las filas con `.loc` o `.iloc`.\n",
    "\n",
    "**Ejemplo:** Cambiar los valores de una fila completa.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un DataFrame de ejemplo\n",
    "data = {'Nombre': ['Juan', 'Ana', 'Luis'], 'Edad': [25, 32, 19], 'Salario': [3000, 4000, 1500]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Modificar todos los valores de la fila con índice 1\n",
    "df.loc[1] = ['Ana María', 33, 4200]\n",
    "\n",
    "print(\"DataFrame después de modificar la fila 1:\\n\", df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Modificación de Valores en Columnas Específicas**\n",
    "\n",
    "Para modificar los valores de una columna específica, puedes asignar directamente nuevos valores a esa columna.\n",
    "\n",
    "**Ejemplo:** Incrementar los salarios en un 10%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Incrementar los valores de la columna 'Salario' en un 10%\n",
    "df['Salario'] *= 1.10\n",
    "\n",
    "print(\"DataFrame después de modificar la columna 'Salario':\\n\", df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Modificación de Valores en Subconjuntos Filtrados**\n",
    "\n",
    "Puedes modificar valores selectivamente aplicando condiciones o máscaras booleanas para identificar las filas o columnas a modificar.\n",
    "\n",
    "**Ejemplo:** Aumentar los salarios para empleados con edad mayor a 30."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Incrementar el salario en un 15% para empleados mayores de 30 años\n",
    "df.loc[df['Edad'] > 30, 'Salario'] *= 1.15\n",
    "\n",
    "print(\"DataFrame después de modificar salarios para empleados mayores de 30 años:\\n\", df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Conclusión**\n",
    "\n",
    "Pandas ofrece herramientas directas y flexibles para modificar valores en filas, columnas o subconjuntos filtrados. Esto permite mantener los datos actualizados y ajustados según las necesidades del análisis o transformación.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **2.3. Manipulación de Estructuras**\n",
    "\n",
    "En Pandas, los DataFrames son estructuras altamente flexibles que permiten realizar modificaciones dinámicas en su contenido y organización. La capacidad de añadir, eliminar o renombrar columnas y filas es fundamental para preparar los datos antes de analizarlos.\n",
    "\n",
    "### **¿Qué incluye la manipulación de estructuras?**\n",
    "1. **Añadir:** Crear nuevas columnas basadas en cálculos o agregar filas adicionales.\n",
    "2. **Eliminar:** Quitar columnas o filas no relevantes para el análisis.\n",
    "3. **Renombrar:** Ajustar los nombres de las columnas o índices para mayor claridad.\n",
    "\n",
    "### **¿Por qué es importante?**\n",
    "Estas operaciones permiten estructurar los datos según las necesidades específicas del análisis, asegurando que los DataFrames sean fáciles de interpretar y manejar.\n",
    "\n",
    "En este módulo, exploraremos las herramientas clave para realizar estas tareas de forma eficiente y flexible.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2.3.1. Añadir Columnas y Filas**\n",
    "\n",
    "En Pandas, puedes agregar nuevas columnas y filas a un DataFrame de manera flexible para expandir la estructura y enriquecer los datos. Estas operaciones son comunes cuando se realizan cálculos o se combinan diferentes datasets.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Agregar Columnas Calculadas**\n",
    "\n",
    "Puedes agregar columnas basadas en cálculos realizados con otras columnas existentes.\n",
    "\n",
    "**Definición:**  \n",
    "`dataframe['nueva_columna'] = operacion_sobre_columnas`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame con columna calculada:\n",
      "   Nombre  Edad  Salario  Impuestos\n",
      "0   Juan    25     3000      450.0\n",
      "1    Ana    32     4000      600.0\n",
      "2   Luis    19     1500      225.0\n"
     ]
    }
   ],
   "source": [
    "# Crear un DataFrame de ejemplo\n",
    "data = {'Nombre': ['Juan', 'Ana', 'Luis'], 'Edad': [25, 32, 19], 'Salario': [3000, 4000, 1500]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Agregar una columna calculada\n",
    "df['Impuestos'] = df['Salario'] * 0.15\n",
    "\n",
    "print(\"DataFrame con columna calculada:\\n\", df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Agregar Filas Individuales**\n",
    "\n",
    "Puedes agregar una fila al final del DataFrame utilizando `loc` o `append`.\n",
    "\n",
    "**Definición:**  \n",
    "`dataframe.loc[indice] = valores`  \n",
    "`dataframe.append({clave: valor}, ignore_index=True)`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agregar una fila utilizando loc\n",
    "df.loc[len(df)] = ['María', 28, 3500, 525, 'Marketing']\n",
    "\n",
    "print(\"DataFrame después de agregar una fila con loc:\\n\", df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Agregar Columnas con Valores Constantes**\n",
    "\n",
    "Puedes agregar columnas con un valor constante para todas las filas.\n",
    "\n",
    "**Definición:**  \n",
    "`dataframe['nueva_columna'] = valor_constante`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame con columna de valores constantes:\n",
      "   Nombre  Edad  Salario  Impuestos Departamento\n",
      "0   Juan    25     3000      450.0       Ventas\n",
      "1    Ana    32     4000      600.0       Ventas\n",
      "2   Luis    19     1500      225.0       Ventas\n"
     ]
    }
   ],
   "source": [
    "# Agregar una columna con un valor constante\n",
    "df['Departamento'] = 'Ventas'\n",
    "\n",
    "print(\"DataFrame con columna de valores constantes:\\n\", df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Concatenar Filas Múltiples**\n",
    "\n",
    "Cuando necesitas agregar varias filas simultáneamente, utiliza `pd.concat` para combinar DataFrames.\n",
    "\n",
    "**Definición:**  \n",
    "`pd.concat([dataframe, nuevo_dataframe], ignore_index=True)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un nuevo DataFrame con filas adicionales\n",
    "nuevas_filas = pd.DataFrame({\n",
    "    'Nombre': ['Carlos', 'Laura'],\n",
    "    'Edad': [30, 27],\n",
    "    'Salario': [3700, 4200],\n",
    "    'Impuestos': [555, 630],\n",
    "    'Departamento': ['Ventas', 'Marketing']\n",
    "})\n",
    "\n",
    "# Concatenar el nuevo DataFrame con el existente\n",
    "df = pd.concat([df, nuevas_filas], ignore_index=True)\n",
    "\n",
    "print(\"DataFrame después de concatenar filas:\\n\", df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **2.3.2. Eliminar Columnas y Filas**\n",
    "\n",
    "La eliminación de columnas y filas en Pandas es una operación común para limpiar y ajustar los datos en un DataFrame. Estas operaciones te permiten:\n",
    "1. **Optimizar los datos:** Quitar columnas o filas innecesarias.\n",
    "2. **Preparar datos para el análisis:** Eliminar elementos irrelevantes o no deseados.\n",
    "3. **Refinar estructuras:** Ajustar la información según las necesidades del proyecto.\n",
    "\n",
    "Pandas ofrece métodos flexibles para estas tareas:\n",
    "- **`drop`:** Permite eliminar columnas o filas especificando sus nombres o índices.\n",
    "- **`pop`:** Elimina columnas devolviendo su contenido como una Serie.\n",
    "- **Máscaras booleanas:** Facilitan la eliminación de filas según condiciones.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Eliminar Columnas Usando `drop`**\n",
    "\n",
    "El método `drop` permite eliminar columnas especificando sus nombres.\n",
    "\n",
    "**Definición:**  \n",
    "`dataframe.drop(columns=['nombre_columna'])`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un DataFrame de ejemplo\n",
    "data = {'Nombre': ['Juan', 'Ana', 'Luis'], 'Edad': [25, 32, 19], 'Salario': [3000, 4000, 1500]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Eliminar la columna 'Salario'\n",
    "df_sin_salario = df.drop(columns=['Salario'])\n",
    "\n",
    "print(\"DataFrame después de eliminar la columna 'Salario':\\n\", df_sin_salario)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Eliminar Columnas Usando `pop`**\n",
    "\n",
    "El método `pop` elimina una columna y devuelve los datos de esa columna como una Serie.\n",
    "\n",
    "**Definición:**  \n",
    "`serie = dataframe.pop('nombre_columna')`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar la columna 'Edad' y devolverla como una Serie\n",
    "columna_edad = df.pop('Edad')\n",
    "\n",
    "print(\"Columna 'Edad' eliminada:\\n\", columna_edad)\n",
    "print(\"\\nDataFrame después de eliminar la columna 'Edad':\\n\", df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Eliminar Filas por Índice Usando `drop`**\n",
    "\n",
    "Puedes eliminar filas especificando sus índices.\n",
    "\n",
    "**Definición:**  \n",
    "`dataframe.drop(index=['indice_fila'])`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un DataFrame de ejemplo con índices personalizados\n",
    "df = pd.DataFrame(data, index=['a', 'b', 'c'])\n",
    "\n",
    "# Eliminar la fila con índice 'b'\n",
    "df_sin_fila_b = df.drop(index=['b'])\n",
    "\n",
    "print(\"DataFrame después de eliminar la fila 'b':\\n\", df_sin_fila_b)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Eliminar Filas Usando Máscaras Booleanas**\n",
    "\n",
    "Las máscaras booleanas permiten eliminar filas que cumplan ciertas condiciones.\n",
    "\n",
    "**Definición:**  \n",
    "`dataframe = dataframe[~condicion]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar filas donde 'Salario' sea menor a 3000\n",
    "df_filtrado = df[df['Salario'] >= 3000]\n",
    "\n",
    "print(\"DataFrame después de eliminar filas con 'Salario' < 3000:\\n\", df_filtrado)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Tabla Resumen: Métodos para Eliminar Columnas y Filas**\n",
    "\n",
    "| **Método**            | **Objetivo**                                    | **Ejemplo**                                |\n",
    "|------------------------|------------------------------------------------|--------------------------------------------|\n",
    "| `drop(columns=[])`    | Eliminar columnas por nombre.                   | `df.drop(columns=['columna'])`             |\n",
    "| `pop()`               | Eliminar columnas y devolver su contenido.      | `serie = df.pop('columna')`                |\n",
    "| `drop(index=[])`      | Eliminar filas especificando índices.           | `df.drop(index=['indice'])`                |\n",
    "| Máscaras Booleanas    | Eliminar filas según una condición lógica.       | `df = df[~condicion]`                      |\n",
    "\n",
    "### **Conclusión**\n",
    "\n",
    "La capacidad de eliminar columnas y filas en Pandas te permite personalizar y optimizar tus DataFrames para el análisis. Dependiendo del caso, puedes usar:\n",
    "- **`drop`** para eliminaciones basadas en nombres o índices.\n",
    "- **`pop`** para extraer y guardar columnas eliminadas.\n",
    "- **Máscaras booleanas** para eliminar filas dinámicamente según condiciones.\n",
    "\n",
    "Estas herramientas hacen que Pandas sea ideal para la preparación y limpieza de datos antes del análisis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **2.3.3. Renombrar Columnas e Índices**\n",
    "\n",
    "La capacidad de renombrar columnas e índices en Pandas es clave para mejorar la claridad y el significado de los datos en un DataFrame. Esto permite ajustar los nombres de las columnas para que sean más descriptivos o adaptar los índices para facilitar el acceso a las filas.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Renombrar Columnas o Índices con `rename`**\n",
    "\n",
    "El método `rename` se utiliza para cambiar los nombres de columnas o índices de un DataFrame.\n",
    "\n",
    "**Definición:**  \n",
    "`dataframe.rename(columns={'columna_actual': 'nueva_columna'}, index={'indice_actual': 'nuevo_indice'})`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un DataFrame de ejemplo\n",
    "data = {'col1': [1, 2, 3], 'col2': [4, 5, 6]}\n",
    "df = pd.DataFrame(data, index=['a', 'b', 'c'])\n",
    "\n",
    "# Renombrar columnas e índices\n",
    "df_renombrado = df.rename(columns={'col1': 'Primera', 'col2': 'Segunda'}, index={'a': 'Fila1', 'b': 'Fila2'})\n",
    "\n",
    "print(\"DataFrame original:\\n\", df)\n",
    "print(\"\\nDataFrame después de renombrar columnas e índices:\\n\", df_renombrado)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Cambiar el Índice con `set_index`**\n",
    "\n",
    "El método `set_index` permite establecer una columna como el índice del DataFrame.\n",
    "\n",
    "**Definición:**  \n",
    "`dataframe.set_index('columna', inplace=True)`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cambiar el índice usando una columna existente\n",
    "data = {'ID': [1, 2, 3], 'Nombre': ['Juan', 'Ana', 'Luis']}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df.set_index('ID', inplace=True)\n",
    "\n",
    "print(\"DataFrame con la columna 'ID' como índice:\\n\", df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Reiniciar el Índice con `reset_index`**\n",
    "\n",
    "El método `reset_index` restaura el índice del DataFrame al valor por defecto y convierte el índice anterior en una columna.\n",
    "\n",
    "**Definición:**  \n",
    "`dataframe.reset_index(inplace=True)`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reiniciar el índice para restaurarlo al valor por defecto\n",
    "df.reset_index(inplace=True)\n",
    "\n",
    "print(\"DataFrame después de reiniciar el índice:\\n\", df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Tabla Resumen: Métodos para Renombrar y Modificar Índices**\n",
    "\n",
    "| **Método**         | **Objetivo**                                                | **Ejemplo**                               |\n",
    "|---------------------|------------------------------------------------------------|-------------------------------------------|\n",
    "| `rename`           | Cambiar nombres de columnas o índices.                     | `df.rename(columns={'col1': 'Primera'})`  |\n",
    "| `set_index`        | Establecer una columna como el índice del DataFrame.        | `df.set_index('columna')`                 |\n",
    "| `reset_index`      | Restaurar el índice al valor por defecto.                   | `df.reset_index()`                        |\n",
    "\n",
    "\n",
    "### **Conclusión**\n",
    "\n",
    "Renombrar columnas e índices en Pandas te permite trabajar con nombres más descriptivos y estructurar los datos de manera más lógica.  \n",
    "- **`rename`** es útil para realizar cambios específicos en nombres.  \n",
    "- **`set_index`** y **`reset_index`** permiten manejar índices de manera flexible, adaptándolos a las necesidades del análisis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **2.4. Operaciones Avanzadas**\n",
    "\n",
    "En el análisis de datos, es común trabajar con múltiples tablas o DataFrames que necesitan ser combinados, unidos o transformados para obtener información útil. Pandas proporciona herramientas avanzadas para realizar estas tareas de manera eficiente, similar a operaciones SQL o transformaciones en hojas de cálculo.\n",
    "\n",
    "### **¿Por qué son importantes las operaciones avanzadas?**\n",
    "1. **Integrar Datos:** Combinar información de diferentes fuentes en un único DataFrame.\n",
    "2. **Transformar Estructuras:** Reorganizar y resumir los datos para un análisis más eficiente.\n",
    "3. **Flexibilidad:** Soporte para operaciones de unión, apilamiento y pivoteo.\n",
    "\n",
    "### **Herramientas Principales**\n",
    "1. **Combinación y Unión de DataFrames:**\n",
    "   - `merge`: Uniones (joins) entre DataFrames basadas en columnas clave.\n",
    "   - `concat`: Apilamiento de DataFrames horizontal o verticalmente.\n",
    "   - `join`: Combinación basada en índices.\n",
    "\n",
    "2. **Pivot y Pivot Tables:**\n",
    "   - `pivot`: Reorganiza los datos para cambiar la estructura del DataFrame.\n",
    "   - `pivot_table`: Crea tablas dinámicas que resumen datos con funciones de agregación.\n",
    "\n",
    "Este módulo cubre estas herramientas avanzadas, esenciales para manipular y transformar datos en análisis complejos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **2.4.1 Combinación y Unión de DataFrames**\n",
    "\n",
    "En proyectos de análisis de datos, es común trabajar con múltiples tablas o DataFrames que contienen información relacionada pero almacenada de forma separada. Pandas proporciona herramientas avanzadas para combinar y unir estos DataFrames, permitiéndote consolidar y estructurar los datos para su análisis.\n",
    "\n",
    "### **¿Por qué es importante la combinación y unión de DataFrames?**\n",
    "1. **Integrar Fuentes de Datos:** Combinar información de diferentes tablas o DataFrames, como bases de datos relacionales, hojas de cálculo o APIs.\n",
    "2. **Estructurar Datos Complejos:** Apilar o unir datos en estructuras más útiles para análisis específicos.\n",
    "3. **Flexibilidad y Precisión:** Realizar uniones basadas en columnas clave o índices, simulando operaciones comunes en bases de datos SQL.\n",
    "\n",
    "### **Herramientas Principales**\n",
    "1. **`merge`:** Realiza uniones similares a las de SQL (inner, left, right, outer).\n",
    "2. **`concat`:** Apila DataFrames horizontal o verticalmente para consolidar datos.\n",
    "3. **`join`:** Combina DataFrames basándose en índices comunes.\n",
    "\n",
    "Estas herramientas son esenciales para combinar datos de forma eficiente, respetando su estructura original o transformándolos según las necesidades del análisis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **`merge`: Uniones Similares a SQL**\n",
    "\n",
    "El método `merge` realiza uniones similares a las que se realizan en SQL. Es útil para combinar DataFrames basándose en columnas clave.\n",
    "\n",
    "**Definición:**  \n",
    "`pd.merge(left, right, on='clave', how='tipo_de_union')`\n",
    "\n",
    "- **`on`:** Especifica la columna común entre los DataFrames.\n",
    "- **`how`:** Define el tipo de unión:\n",
    "  - `inner` (predeterminado): Devuelve solo los valores comunes.\n",
    "  - `left`: Todos los valores de `left` y los comunes de `right`.\n",
    "  - `right`: Todos los valores de `right` y los comunes de `left`.\n",
    "  - `outer`: Combina todos los valores de ambos DataFrames.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear dos DataFrames de ejemplo\n",
    "df1 = pd.DataFrame({'ID': [1, 2, 3], 'Nombre': ['Juan', 'Ana', 'Luis']})\n",
    "df2 = pd.DataFrame({'ID': [2, 3, 4], 'Salario': [4000, 3500, 3000]})\n",
    "\n",
    "# Realizar un merge (inner join)\n",
    "df_merge = pd.merge(df1, df2, on='ID', how='inner')\n",
    "\n",
    "print(\"DataFrame combinado (inner join):\\n\", df_merge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **`concat`: Apilamiento de DataFrames**\n",
    "\n",
    "El método `concat` permite combinar DataFrames apilándolos horizontal o verticalmente.\n",
    "\n",
    "**Definición:**  \n",
    "`pd.concat([df1, df2], axis=0, ignore_index=True)`\n",
    "\n",
    "- **`axis`:** Define la dirección del apilamiento:\n",
    "  - `0`: Apilamiento vertical (filas).\n",
    "  - `1`: Apilamiento horizontal (columnas).\n",
    "- **`ignore_index`:** Si es `True`, reinicia el índice en el DataFrame resultante.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear dos DataFrames de ejemplo\n",
    "df1 = pd.DataFrame({'Nombre': ['Juan', 'Ana'], 'Edad': [25, 32]})\n",
    "df2 = pd.DataFrame({'Nombre': ['Luis', 'María'], 'Edad': [19, 45]})\n",
    "\n",
    "# Concatenar verticalmente\n",
    "df_concat = pd.concat([df1, df2], axis=0, ignore_index=True)\n",
    "\n",
    "print(\"DataFrame concatenado (vertical):\\n\", df_concat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **`join`: Combinar por Índices**\n",
    "\n",
    "El método `join` combina DataFrames basándose en sus índices, siendo útil para operaciones con índices alineados.\n",
    "\n",
    "**Definición:**  \n",
    "`df1.join(df2, how='tipo_de_union')`\n",
    "\n",
    "- **`how`:** Define el tipo de unión:\n",
    "  - `left`: Todos los índices de `df1`.\n",
    "  - `right`: Todos los índices de `df2`.\n",
    "  - `inner`: Solo índices comunes.\n",
    "  - `outer`: Combina todos los índices de ambos DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear dos DataFrames de ejemplo con índices alineados\n",
    "df1 = pd.DataFrame({'Nombre': ['Juan', 'Ana', 'Luis']}, index=[1, 2, 3])\n",
    "df2 = pd.DataFrame({'Salario': [3000, 4000, 3500]}, index=[1, 2, 3])\n",
    "\n",
    "# Realizar un join (left join)\n",
    "df_join = df1.join(df2, how='left')\n",
    "\n",
    "print(\"DataFrame combinado (left join):\\n\", df_join)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Tabla Resumen: Métodos de Combinación y Unión**\n",
    "\n",
    "| **Método**            | **Descripción**                                    | **Ejemplo**                                      |\n",
    "|------------------------|----------------------------------------------------|------------------------------------------------|\n",
    "| `merge`               | Combina DataFrames basándose en columnas clave.    | `pd.merge(df1, df2, on='columna')`             |\n",
    "| `concat`              | Apila DataFrames horizontal o verticalmente.       | `pd.concat([df1, df2], axis=0)`                |\n",
    "| `join`                | Combina DataFrames basándose en índices.           | `df1.join(df2, how='outer')`                   |\n",
    "\n",
    "### **Conclusión**\n",
    "\n",
    "La combinación y unión de DataFrames es fundamental para consolidar y analizar datos en Pandas.  \n",
    "- **`merge`** es ideal para uniones basadas en columnas clave.  \n",
    "- **`concat`** permite apilar DataFrames de manera flexible.  \n",
    "- **`join`** es útil cuando trabajas con índices alineados.\n",
    "\n",
    "Estas herramientas te ofrecen flexibilidad y potencia para trabajar con múltiples datasets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **2.4.2 Pivot y Pivot Tables**\n",
    "\n",
    "En Pandas, las herramientas `pivot` y `pivot_table` permiten transformar y resumir datos en un DataFrame, creando estructuras tabulares más organizadas y útiles para el análisis.\n",
    "\n",
    "### **¿Por qué usar Pivot y Pivot Tables?**\n",
    "1. **Reorganizar Datos:** Convertir valores de columnas en etiquetas y reorganizar los datos en una nueva estructura.\n",
    "2. **Resumen de Datos:** Generar resúmenes de datos utilizando funciones de agregación como suma, promedio o conteo.\n",
    "3. **Facilidad de Análisis:** Explorar relaciones entre variables de forma eficiente y visual.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **`pivot`: Reorganización de Datos**\n",
    "\n",
    "El método `pivot` permite transformar un DataFrame convirtiendo:\n",
    "- Una columna en el índice.\n",
    "- Otra columna en las etiquetas de las columnas.\n",
    "- Una tercera columna en los valores.\n",
    "\n",
    "**Definición:**  \n",
    "`dataframe.pivot(index='fila', columns='columna', values='valor')`\n",
    "\n",
    "**Nota:** `pivot` requiere que las combinaciones de índice y columna sean únicas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un DataFrame de ejemplo\n",
    "data = {\n",
    "    'Mes': ['Enero', 'Enero', 'Febrero', 'Febrero'],\n",
    "    'Producto': ['A', 'B', 'A', 'B'],\n",
    "    'Ventas': [100, 150, 200, 250]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Reorganizar datos con pivot\n",
    "df_pivot = df.pivot(index='Mes', columns='Producto', values='Ventas')\n",
    "\n",
    "print(\"DataFrame original:\\n\", df)\n",
    "print(\"\\nDataFrame reorganizado con pivot:\\n\", df_pivot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **`pivot_table`: Tablas Dinámicas**\n",
    "\n",
    "El método `pivot_table` extiende la funcionalidad de `pivot`, permitiendo:\n",
    "- Aplicar funciones de agregación.\n",
    "- Manejar valores duplicados.\n",
    "- Trabajar con datos más complejos.\n",
    "\n",
    "**Definición:**  \n",
    "`dataframe.pivot_table(index='fila', columns='columna', values='valor', aggfunc='funcion')`\n",
    "\n",
    "**Parámetros Clave:**\n",
    "- **`aggfunc`:** Función de agregación (por defecto, `mean`).\n",
    "- **`fill_value`:** Valor con el que llenar celdas vacías.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un DataFrame con valores duplicados\n",
    "data = {\n",
    "    'Mes': ['Enero', 'Enero', 'Febrero', 'Febrero'],\n",
    "    'Producto': ['A', 'A', 'B', 'B'],\n",
    "    'Ventas': [100, 200, 300, 400]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Crear una tabla dinámica con pivot_table\n",
    "df_pivot_table = df.pivot_table(index='Mes', columns='Producto', values='Ventas', aggfunc='sum')\n",
    "\n",
    "print(\"DataFrame original:\\n\", df)\n",
    "print(\"\\nTabla dinámica con pivot_table:\\n\", df_pivot_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Tabla Resumen: Diferencias entre `pivot` y `pivot_table`**\n",
    "\n",
    "| **Método**       | **Uso Principal**                                  | **Diferencia Clave**                                      |\n",
    "|-------------------|---------------------------------------------------|----------------------------------------------------------|\n",
    "| `pivot`          | Reorganiza datos basándose en combinaciones únicas.| Requiere combinaciones únicas de índice y columna.        |\n",
    "| `pivot_table`    | Crea tablas dinámicas con agregaciones.            | Maneja valores duplicados y permite aplicar funciones.    |\n",
    "\n",
    "\n",
    "### **Conclusión**\n",
    "\n",
    "Las herramientas `pivot` y `pivot_table` son fundamentales para transformar y analizar datos de manera estructurada:\n",
    "- Usa **`pivot`** para reorganizar datos si las combinaciones son únicas.\n",
    "- Usa **`pivot_table`** cuando necesitas realizar agregaciones o manejar duplicados.\n",
    "\n",
    "Estas herramientas hacen que la organización y análisis de datos sean más eficientes y flexibles.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **2.5. Agregaciones y Agrupaciones**\n",
    "\n",
    "En el análisis de datos, a menudo es necesario resumir grandes volúmenes de información para extraer patrones, tendencias o insights significativos. Las operaciones de **agregación** y **agrupación** en Pandas permiten realizar este tipo de análisis de manera eficiente y flexible.\n",
    "\n",
    "### **¿Qué son las Agregaciones y Agrupaciones?**\n",
    "1. **Agregaciones:** Son cálculos que condensan un conjunto de valores en una sola medida, como sumas, promedios o máximos.\n",
    "2. **Agrupaciones:** Dividen los datos en subconjuntos basados en valores compartidos de una o más columnas, para luego aplicar funciones de agregación.\n",
    "\n",
    "---\n",
    "\n",
    "### **¿Por qué usar estas técnicas?**\n",
    "1. **Resumir Datos:** Reducir la complejidad de los datos y centrarse en métricas clave.\n",
    "2. **Analizar Grupos:** Comparar tendencias o patrones dentro de subgrupos específicos.\n",
    "3. **Flexibilidad:** Personalizar cálculos y adaptarlos a las necesidades del análisis.\n",
    "\n",
    "---\n",
    "\n",
    "### **Ejemplos Comunes de Uso**\n",
    "1. **Agrupaciones simples:** Resumir ventas por categoría de producto.\n",
    "2. **Agrupaciones múltiples:** Calcular promedios de salario por departamento y ciudad.\n",
    "3. **Funciones personalizadas:** Aplicar métricas específicas para cada grupo, como el rango de valores o el coeficiente de variación.\n",
    "\n",
    "En este módulo, aprenderás a usar las herramientas de Pandas para realizar estas operaciones y adaptar los resultados a tus necesidades analíticas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2.5.1 Uso de `groupby`**\n",
    "\n",
    "El método `groupby` en Pandas permite dividir un DataFrame en grupos basados en los valores de una o más columnas. Una vez agrupados, puedes aplicar funciones de agregación o transformaciones personalizadas para analizar los datos dentro de cada grupo.\n",
    "\n",
    "### **¿Por qué usar `groupby`?**\n",
    "1. **Agrupaciones Simples:** Analizar datos segmentados por una categoría específica.\n",
    "2. **Agrupaciones Múltiples:** Explorar patrones basados en combinaciones de varias categorías.\n",
    "3. **Agregaciones Personalizadas:** Aplicar funciones propias para obtener métricas más avanzadas.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Agrupaciones Simples**\n",
    "\n",
    "Las agrupaciones simples dividen los datos basándose en una sola columna y permiten aplicar funciones de agregación a cada grupo.\n",
    "\n",
    "**Definición:**  \n",
    "`dataframe.groupby('columna')['otra_columna'].funcion()`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un DataFrame de ejemplo\n",
    "data = {'Categoría': ['A', 'B', 'A', 'B', 'C'], 'Ventas': [100, 200, 150, 300, 400]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Calcular la suma de ventas por categoría\n",
    "suma_ventas = df.groupby('Categoría')['Ventas'].sum()\n",
    "\n",
    "print(\"Suma de ventas por categoría:\\n\", suma_ventas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Agrupaciones Múltiples**\n",
    "\n",
    "Las agrupaciones múltiples permiten dividir los datos utilizando más de una columna como clave.\n",
    "\n",
    "**Definición:**  \n",
    "`dataframe.groupby(['columna1', 'columna2'])['otra_columna'].funcion()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un DataFrame con múltiples categorías\n",
    "data = {'Región': ['Norte', 'Norte', 'Sur', 'Sur', 'Este'],\n",
    "        'Categoría': ['A', 'B', 'A', 'B', 'C'],\n",
    "        'Ventas': [100, 200, 150, 300, 400]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Calcular el promedio de ventas por región y categoría\n",
    "promedio_ventas = df.groupby(['Región', 'Categoría'])['Ventas'].mean()\n",
    "\n",
    "print(\"Promedio de ventas por región y categoría:\\n\", promedio_ventas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Agregaciones Personalizadas**\n",
    "\n",
    "Pandas permite aplicar funciones personalizadas a cada grupo utilizando `apply` o `agg`.\n",
    "\n",
    "**Definición:**  \n",
    "`dataframe.groupby('columna')['otra_columna'].apply(funcion)`  \n",
    "`dataframe.groupby('columna').agg({'otra_columna': funcion})`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir una función personalizada\n",
    "def rango(datos):\n",
    "    return datos.max() - datos.min()\n",
    "\n",
    "# Calcular el rango de ventas por categoría\n",
    "rango_ventas = df.groupby('Categoría')['Ventas'].apply(rango)\n",
    "\n",
    "print(\"Rango de ventas por categoría:\\n\", rango_ventas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Tabla Resumen: Uso de `groupby`**\n",
    "\n",
    "| **Método**                   | **Descripción**                                         | **Ejemplo**                                      |\n",
    "|-------------------------------|-------------------------------------------------------|------------------------------------------------|\n",
    "| `groupby('columna').sum()`   | Calcula la suma para cada grupo.                       | `df.groupby('Categoría')['Ventas'].sum()`      |\n",
    "| `groupby(['col1', 'col2'])`  | Divide los datos basándose en varias columnas clave.   | `df.groupby(['Región', 'Categoría']).mean()`   |\n",
    "| `apply(funcion)`             | Aplica una función personalizada a cada grupo.         | `df.groupby('Categoría')['Ventas'].apply(func)`|\n",
    "| `agg({'col': funcion})`      | Permite agregar múltiples funciones a diferentes columnas.| `df.groupby('Categoría').agg({'Ventas': 'sum'})`|\n",
    "\n",
    "### **Conclusión**\n",
    "\n",
    "El método `groupby` en Pandas es una herramienta poderosa para dividir, agrupar y analizar datos de manera eficiente.  \n",
    "- Usa **agrupaciones simples** para métricas básicas.  \n",
    "- Usa **agrupaciones múltiples** para explorar combinaciones complejas.  \n",
    "- Aplica **funciones personalizadas** para adaptarte a necesidades específicas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2.5.2 Estadísticas Básicas**\n",
    "\n",
    "Pandas ofrece métodos integrados que permiten calcular estadísticas descriptivas directamente sobre columnas o filas de un DataFrame. Estas funciones son esenciales para obtener resúmenes rápidos y analizar la distribución de los datos.\n",
    "\n",
    "### **¿Por qué usar estadísticas básicas?**\n",
    "1. **Explorar Datos:** Obtener información sobre la distribución, tendencia y dispersión de los datos.\n",
    "2. **Identificar Patrones:** Comparar métricas como promedio, mínimo o máximo entre diferentes variables.\n",
    "3. **Facilidad y Eficiencia:** Métodos rápidos y optimizados para grandes volúmenes de datos.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Suma de Valores (`sum`)**\n",
    "\n",
    "El método `sum` calcula la suma de todos los valores en una Serie o columna. También puede aplicarse a todo el DataFrame, sumando por columnas o filas.\n",
    "\n",
    "**Definición:**  \n",
    "`serie.sum()`  \n",
    "`dataframe.sum(axis=0)`\n",
    "\n",
    "**Parámetros Clave:**\n",
    "- **`axis=0`:** Suma por columnas (predeterminado).\n",
    "- **`axis=1`:** Suma por filas.\n",
    "- **`skipna`:** Si es `True` (predeterminado), ignora valores `NaN`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un DataFrame de ejemplo\n",
    "data = {'Producto': ['A', 'B', 'C'], 'Ventas': [100, 200, 150], 'Devoluciones': [10, 5, 8]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Suma de una columna específica\n",
    "suma_ventas = df['Ventas'].sum()\n",
    "\n",
    "# Suma por columnas\n",
    "suma_columnas = df.sum(axis=0)\n",
    "\n",
    "# Suma por filas\n",
    "suma_filas = df.sum(axis=1)\n",
    "\n",
    "print(\"Suma de ventas:\", suma_ventas)\n",
    "print(\"Suma por columnas:\\n\", suma_columnas)\n",
    "print(\"Suma por filas:\\n\", suma_filas)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Promedio de Valores (`mean`)**\n",
    "\n",
    "El método `mean` calcula el promedio (media aritmética) de los valores en una Serie o columna.\n",
    "\n",
    "**Definición:**  \n",
    "`serie.mean()`  \n",
    "`dataframe.mean(axis=0)`\n",
    "\n",
    "**Parámetros Clave:**\n",
    "- **`axis=0`:** Calcula el promedio por columnas (predeterminado).\n",
    "- **`axis=1`:** Calcula el promedio por filas.\n",
    "- **`skipna`:** Ignora valores `NaN` si es `True` (predeterminado)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular el promedio de una columna\n",
    "promedio_ventas = df['Ventas'].mean()\n",
    "\n",
    "# Promedio por columnas\n",
    "promedio_columnas = df.mean(axis=0)\n",
    "\n",
    "# Promedio por filas\n",
    "promedio_filas = df.mean(axis=1)\n",
    "\n",
    "print(\"Promedio de ventas:\", promedio_ventas)\n",
    "print(\"Promedio por columnas:\\n\", promedio_columnas)\n",
    "print(\"Promedio por filas:\\n\", promedio_filas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Valor Mínimo (`min`)**\n",
    "\n",
    "El método `min` devuelve el valor mínimo en una Serie o columna.\n",
    "\n",
    "**Definición:**  \n",
    "`serie.min()`  \n",
    "`dataframe.min(axis=0)`\n",
    "\n",
    "**Parámetros Clave:**\n",
    "- **`axis=0`:** Devuelve el mínimo por columnas (predeterminado).\n",
    "- **`axis=1`:** Devuelve el mínimo por filas.\n",
    "- **`skipna`:** Ignora valores `NaN` si es `True`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valor mínimo de una columna\n",
    "minimo_ventas = df['Ventas'].min()\n",
    "\n",
    "# Mínimo por columnas\n",
    "minimo_columnas = df.min(axis=0)\n",
    "\n",
    "# Mínimo por filas\n",
    "minimo_filas = df.min(axis=1)\n",
    "\n",
    "print(\"Mínimo de ventas:\", minimo_ventas)\n",
    "print(\"Mínimo por columnas:\\n\", minimo_columnas)\n",
    "print(\"Mínimo por filas:\\n\", minimo_filas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Valor Máximo (`max`)**\n",
    "\n",
    "El método `max` devuelve el valor máximo en una Serie o columna.\n",
    "\n",
    "**Definición:**  \n",
    "`serie.max()`  \n",
    "`dataframe.max(axis=0)`\n",
    "\n",
    "**Parámetros Clave:**\n",
    "- **`axis=0`:** Devuelve el máximo por columnas (predeterminado).\n",
    "- **`axis=1`:** Devuelve el máximo por filas.\n",
    "- **`skipna`:** Ignora valores `NaN` si es `True`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valor máximo de una columna\n",
    "maximo_ventas = df['Ventas'].max()\n",
    "\n",
    "# Máximo por columnas\n",
    "maximo_columnas = df.max(axis=0)\n",
    "\n",
    "# Máximo por filas\n",
    "maximo_filas = df.max(axis=1)\n",
    "\n",
    "print(\"Máximo de ventas:\", maximo_ventas)\n",
    "print(\"Máximo por columnas:\\n\", maximo_columnas)\n",
    "print(\"Máximo por filas:\\n\", maximo_filas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Estadísticas por Columnas o Filas**\n",
    "\n",
    "Pandas permite aplicar estas estadísticas a todo el DataFrame, especificando si se calcula por columnas (`axis=0`, predeterminado) o por filas (`axis=1`).\n",
    "\n",
    "**Definición:**  \n",
    "`dataframe.metodo(axis=0)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estadísticas por columnas\n",
    "suma_columnas = df.sum(axis=0)\n",
    "\n",
    "# Estadísticas por filas\n",
    "suma_filas = df.sum(axis=1)\n",
    "\n",
    "print(\"Suma por columnas:\\n\", suma_columnas)\n",
    "print(\"\\nSuma por filas:\\n\", suma_filas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Tabla Resumen: Métodos Básicos**\n",
    "\n",
    "| **Método**   | **Descripción**                               | **Ejemplo**                          |\n",
    "|--------------|-----------------------------------------------|--------------------------------------|\n",
    "| `sum`        | Calcula la suma de los valores.               | `df['Ventas'].sum()`                |\n",
    "| `mean`       | Calcula el promedio de los valores.           | `df['Devoluciones'].mean()`         |\n",
    "| `min`        | Encuentra el valor mínimo.                    | `df['Ventas'].min()`                |\n",
    "| `max`        | Encuentra el valor máximo.                    | `df['Ventas'].max()`                |\n",
    "| `axis=0`     | Aplica la operación por columnas.             | `df.sum(axis=0)`                    |\n",
    "| `axis=1`     | Aplica la operación por filas.                | `df.sum(axis=1)`                    |\n",
    "\n",
    "\n",
    "### **Conclusión**\n",
    "\n",
    "Las estadísticas básicas en Pandas permiten explorar y analizar rápidamente los datos en un DataFrame.  \n",
    "- Usa **métodos individuales** (`sum`, `mean`, `min`, `max`) para analizar columnas específicas.  \n",
    "- Usa **estadísticas por filas o columnas** para comparar y resumir datos a nivel global.  \n",
    "\n",
    "Estas herramientas son esenciales para obtener insights iniciales de cualquier dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **2.6. Transformación y Limpieza de Datos**\n",
    "\n",
    "La limpieza y transformación de datos son procesos clave en cualquier flujo de trabajo de análisis de datos. Pandas proporciona herramientas robustas para manejar valores faltantes, eliminar duplicados y transformar datos, garantizando la calidad y precisión en el análisis.\n",
    "\n",
    "### **¿Por qué es crucial la limpieza y transformación?**\n",
    "1. **Evitar Errores:** Los valores nulos o inconsistentes pueden sesgar resultados.\n",
    "2. **Optimizar Análisis:** Los datos limpios son más fáciles de explorar y analizar.\n",
    "3. **Preparar Datos:** Transformar datos en un formato adecuado para modelos y visualizaciones.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Detección y Manejo de Valores Nulos**\n",
    "\n",
    "Los valores nulos (`NaN`) son comunes en datasets y pueden afectar cálculos, visualizaciones y modelos predictivos. Pandas ofrece herramientas flexibles para identificar y manejar estos valores, asegurando que los datos sean consistentes y aptos para el análisis.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Identificar Valores Nulos**\n",
    "\n",
    "Para detectar valores nulos, Pandas utiliza los métodos:\n",
    "- **`isnull`:** Devuelve una máscara booleana donde los valores nulos son `True`.\n",
    "- **`notnull`:** Devuelve una máscara booleana donde los valores no nulos son `True`.\n",
    "\n",
    "**Definición:**  \n",
    "`dataframe.isnull()`  \n",
    "`dataframe.notnull()`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un DataFrame con valores nulos\n",
    "data = {'A': [1, 2, np.nan], 'B': [4, np.nan, 6], 'C': [7, 8, 9]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Identificar valores nulos\n",
    "nulos = df.isnull()\n",
    "\n",
    "# Identificar valores no nulos\n",
    "no_nulos = df.notnull()\n",
    "\n",
    "print(\"Valores nulos:\\n\", nulos)\n",
    "print(\"\\nValores no nulos:\\n\", no_nulos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Rellenar Valores Faltantes**\n",
    "\n",
    "El método `fillna` permite reemplazar los valores nulos con otros valores. Esto es útil para evitar que los valores nulos afecten cálculos o visualizaciones.\n",
    "\n",
    "**Definición:**  \n",
    "`dataframe.fillna(valor, method='metodo')`\n",
    "\n",
    "**Parámetros Clave:**\n",
    "- **`valor`:** Valor con el que rellenar los nulos (por ejemplo, 0, promedio, mediana).\n",
    "- **`method`:** Método de propagación (`ffill` para hacia adelante o `bfill` para hacia atrás).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rellenar valores nulos con un valor constante\n",
    "df_rellenado_constante = df.fillna(0)\n",
    "\n",
    "# Rellenar valores nulos con el promedio de la columna\n",
    "df_rellenado_promedio = df.fillna(df.mean())\n",
    "\n",
    "print(\"DataFrame con valores nulos rellenados con 0:\\n\", df_rellenado_constante)\n",
    "print(\"\\nDataFrame con valores nulos rellenados con el promedio:\\n\", df_rellenado_promedio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Eliminar Valores Nulos**\n",
    "\n",
    "El método `dropna` elimina filas o columnas que contienen valores nulos.\n",
    "\n",
    "**Definición:**  \n",
    "`dataframe.dropna(axis=0, how='any')`\n",
    "\n",
    "**Parámetros Clave:**\n",
    "- **`axis=0`:** Elimina filas con valores nulos (predeterminado).\n",
    "- **`axis=1`:** Elimina columnas con valores nulos.\n",
    "- **`how='any'`:** Elimina si hay al menos un valor nulo.\n",
    "- **`how='all'`:** Elimina si todos los valores son nulos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar filas con al menos un valor nulo\n",
    "df_sin_nulos_filas = df.dropna(axis=0, how='any')\n",
    "\n",
    "# Eliminar columnas con todos los valores nulos\n",
    "df_sin_nulos_columnas = df.dropna(axis=1, how='all')\n",
    "\n",
    "print(\"DataFrame después de eliminar filas con valores nulos:\\n\", df_sin_nulos_filas)\n",
    "print(\"\\nDataFrame después de eliminar columnas con todos valores nulos:\\n\", df_sin_nulos_columnas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Detección y Eliminación de Duplicados**\n",
    "\n",
    "En muchos datasets, es común encontrar datos duplicados que pueden distorsionar resultados, aumentar redundancia o inflar estadísticas. Pandas ofrece herramientas para identificar y eliminar estas duplicidades de manera eficiente.\n",
    "\n",
    "---\n",
    "\n",
    "### **Identificar Duplicados**\n",
    "\n",
    "El método `duplicated` genera una máscara booleana que indica si una fila es duplicada en comparación con las anteriores. Este método es útil para detectar duplicados rápidamente.\n",
    "\n",
    "**Definición:**  \n",
    "`dataframe.duplicated()`\n",
    "\n",
    "**Parámetros Clave:**\n",
    "- **`subset`:** Especifica las columnas en las que buscar duplicados (por defecto, todas las columnas).\n",
    "- **`keep`:** Determina cuál duplicado marcar como no duplicado:\n",
    "  - **`'first'` (predeterminado):** Marca duplicados excepto la primera aparición.\n",
    "  - **`'last':`** Marca duplicados excepto la última aparición.\n",
    "  - **`False`:** Marca todas las apariciones como duplicadas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un DataFrame con filas duplicadas\n",
    "data = {'ID': [1, 2, 2, 4], 'Nombre': ['Juan', 'Ana', 'Ana', 'Luis']}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Identificar duplicados\n",
    "duplicados = df.duplicated()\n",
    "\n",
    "print(\"Máscara de duplicados:\\n\", duplicados)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Eliminar Duplicados**\n",
    "\n",
    "El método `drop_duplicates` elimina filas duplicadas del DataFrame, conservando solo la primera o última ocurrencia según lo especificado.\n",
    "\n",
    "**Definición:**  \n",
    "`dataframe.drop_duplicates(keep='first')`\n",
    "\n",
    "**Parámetros Clave:**\n",
    "- **`subset`:** Columnas específicas para identificar duplicados.\n",
    "- **`keep`:** Especifica qué duplicado conservar:\n",
    "  - **`'first'`:** Conserva la primera aparición (predeterminado).\n",
    "  - **`'last'`:** Conserva la última aparición.\n",
    "  - **`False`:** Elimina todas las filas duplicadas.\n",
    "- **`inplace`:** Si es `True`, modifica el DataFrame original.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar duplicados conservando solo la primera ocurrencia\n",
    "df_sin_duplicados = df.drop_duplicates(keep='first')\n",
    "\n",
    "# Eliminar duplicados en una columna específica\n",
    "df_sin_duplicados_nombre = df.drop_duplicates(subset=['Nombre'], keep='last')\n",
    "\n",
    "print(\"DataFrame sin duplicados (conservando primera aparición):\\n\", df_sin_duplicados)\n",
    "print(\"\\nDataFrame sin duplicados basados en 'Nombre':\\n\", df_sin_duplicados_nombre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Aplicar Funciones con `apply`**\n",
    "\n",
    "El método `apply` permite aplicar funciones personalizadas a columnas o filas de un DataFrame.\n",
    "\n",
    "**Definición:**  \n",
    "`dataframe['columna'].apply(funcion)`\n",
    "\n",
    "**Casos de Uso:**\n",
    "- Aplicar transformaciones a todos los valores de una columna.\n",
    "- Usar funciones lambda para transformaciones rápidas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un DataFrame de ejemplo\n",
    "data = {'Ventas': [100, 200, 300]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Definir una función personalizada\n",
    "def agregar_iva(valor):\n",
    "    return valor * 1.21\n",
    "\n",
    "# Aplicar la función personalizada a la columna 'Ventas'\n",
    "df['Ventas con IVA'] = df['Ventas'].apply(agregar_iva)\n",
    "\n",
    "print(\"DataFrame con IVA aplicado:\\n\", df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Transformar Valores con `map`**\n",
    "\n",
    "El método `map` transforma valores elemento a elemento en Series. Es útil para:\n",
    "- Reemplazar valores.\n",
    "- Realizar cálculos rápidos.\n",
    "- Aplicar transformaciones usando diccionarios o funciones.\n",
    "\n",
    "**Definición:**  \n",
    "`serie.map(funcion_o_diccionario)`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear una Serie de ejemplo\n",
    "df['Categoría'] = ['A', 'B', 'C']\n",
    "\n",
    "# Usar map para transformar elementos\n",
    "transformacion = {'A': 'Alta', 'B': 'Media', 'C': 'Baja'}\n",
    "df['Nivel'] = df['Categoría'].map(transformacion)\n",
    "\n",
    "print(\"DataFrame con valores transformados:\\n\", df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Operaciones Vectorizadas**\n",
    "\n",
    "Las operaciones vectorizadas permiten realizar cálculos directamente sobre columnas, aprovechando la velocidad y optimización de NumPy.\n",
    "\n",
    "**Definición:**  \n",
    "`dataframe['columna'] operacion valor`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear una columna calculada usando operaciones vectorizadas\n",
    "df['Ventas con Descuento'] = df['Ventas'] * 0.90\n",
    "\n",
    "print(\"DataFrame con descuento aplicado:\\n\", df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Tabla Resumen: Métodos de Limpieza y Transformación**\n",
    "\n",
    "| **Método**            | **Objetivo**                                      | **Ejemplo**                                |\n",
    "|------------------------|--------------------------------------------------|--------------------------------------------|\n",
    "| `isnull`              | Identificar valores nulos.                       | `df.isnull()`                              |\n",
    "| `notnull`             | Identificar valores no nulos.                    | `df.notnull()`                             |\n",
    "| `fillna`              | Rellenar valores nulos.                          | `df.fillna(0)`                             |\n",
    "| `dropna`              | Eliminar filas o columnas con valores nulos.     | `df.dropna(axis=0, how='any')`             |\n",
    "| `duplicated`          | Identificar filas duplicadas.                    | `df.duplicated()`                          |\n",
    "| `drop_duplicates`     | Eliminar filas duplicadas.                       | `df.drop_duplicates(keep='first')`         |\n",
    "| `apply`               | Aplicar funciones personalizadas a columnas.     | `df['columna'].apply(funcion)`             |\n",
    "| `map`                 | Aplicar transformaciones elemento a elemento.    | `serie.map(funcion)`                       |\n",
    "| `Operaciones Vectorizadas`| Realizar cálculos directamente en columnas.  | `df['Ventas'] * 1.10`                     |\n",
    "\n",
    "### **Conclusión**\n",
    "\n",
    "Pandas proporciona herramientas potentes para manejar valores nulos, duplicados y transformar columnas.  \n",
    "- Usa **`isnull` y `notnull`** para detectar valores faltantes.  \n",
    "- Usa **`fillna` y `dropna`** para manejar nulos de manera eficiente.  \n",
    "- Usa **`duplicated` y `drop_duplicates`** para eliminar redundancias en tus datos.  \n",
    "- Aplica **`apply`, `map` y operaciones vectorizadas** para transformar columnas de manera personalizada.\n",
    "\n",
    "Estas herramientas son esenciales para garantizar la calidad y consistencia en el análisis de datos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **2.7. Análisis de Datos**\n",
    "\n",
    "El análisis de datos es una etapa crucial en cualquier proceso de manipulación de datos. Pandas proporciona herramientas avanzadas para explorar, resumir y exportar información de manera eficiente. Estas funcionalidades permiten extraer insights clave y preparar los datos para análisis más profundos o para integrarlos en sistemas externos.\n",
    "\n",
    "### **¿Qué aprenderás en este módulo?**\n",
    "1. **Explorar Datos con `describe`:** Generar resúmenes estadísticos rápidos para entender la distribución y características de los datos.\n",
    "2. **Calcular Estadísticas Básicas:** Aplicar métodos como suma, promedio, mínimos y máximos para obtener métricas relevantes.\n",
    "3. **Exportar Resultados:** Guardar DataFrames en formatos como CSV o Excel, facilitando la integración con herramientas externas o la distribución de los resultados.\n",
    "\n",
    "### **¿Por qué es importante el análisis de datos?**\n",
    "1. **Visión General:** Proporciona una descripción inicial de los datos, destacando patrones y posibles problemas.\n",
    "2. **Toma de Decisiones:** Permite calcular métricas clave que informan decisiones basadas en datos.\n",
    "3. **Documentación y Presentación:** Exportar resultados en formatos accesibles facilita la comunicación y documentación del trabajo realizado.\n",
    "\n",
    "En este módulo, aprenderás a usar herramientas fundamentales de Pandas para explorar, analizar y exportar datos de manera eficiente y profesional.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2.7.1 Uso de `describe` para Resúmenes Estadísticos**\n",
    "\n",
    "El método `describe` de Pandas genera un resumen estadístico básico del DataFrame, proporcionando una visión general de los datos. Este método es esencial para comprender rápidamente las características clave de las columnas, tanto numéricas como categóricas.\n",
    "\n",
    "---\n",
    "\n",
    "### **Beneficios de Usar `describe`**\n",
    "1. **Rapidez:** Genera resúmenes estadísticos en una sola línea de código.\n",
    "2. **Flexibilidad:** Admite personalización según los tipos de datos y métricas requeridas.\n",
    "3. **Visión General:** Proporciona una descripción clara de las distribuciones y características de los datos.\n",
    "\n",
    "### **Aplicaciones Comunes**\n",
    "- **Análisis Exploratorio:** Obtener un resumen rápido al comenzar un análisis de datos.\n",
    "- **Detección de Problemas:** Identificar columnas con valores atípicos o faltantes.\n",
    "- **Validación de Datos:** Verificar si las características de los datos coinciden con las expectativas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resumen estadístico básico:\n",
      "            Ventas\n",
      "count    4.000000\n",
      "mean   250.000000\n",
      "std    129.099445\n",
      "min    100.000000\n",
      "25%    175.000000\n",
      "50%    250.000000\n",
      "75%    325.000000\n",
      "max    400.000000\n"
     ]
    }
   ],
   "source": [
    "# Crear un DataFrame de ejemplo\n",
    "data = {'Ventas': [100, 200, 300, 400], 'Categoría': ['A', 'B', 'A', 'C']}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Generar un resumen estadístico básico\n",
    "resumen = df.describe()\n",
    "\n",
    "print(\"Resumen estadístico básico:\\n\", resumen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Aplicaciones Comunes**\n",
    "\n",
    "#### **1. Análisis Exploratorio**\n",
    "Permite obtener un resumen rápido al comenzar un análisis de datos.\n",
    "\n",
    "**Ejemplo:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resumen numérico:\n",
      "             Edad      Salario   Impuestos\n",
      "count   3.000000     3.000000    3.000000\n",
      "mean   25.333333  2833.333333  425.000000\n",
      "std     6.506407  1258.305739  188.745861\n",
      "min    19.000000  1500.000000  225.000000\n",
      "25%    22.000000  2250.000000  337.500000\n",
      "50%    25.000000  3000.000000  450.000000\n",
      "75%    28.500000  3500.000000  525.000000\n",
      "max    32.000000  4000.000000  600.000000\n"
     ]
    }
   ],
   "source": [
    "# Resumen de columnas numéricas para entender la distribución de los datos\n",
    "resumen_numerico = df.describe()\n",
    "\n",
    "print(\"Resumen numérico:\\n\", resumen_numerico)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **2. Detección de Problemas**\n",
    "Identifica columnas con valores atípicos, distribuciones inesperadas o datos faltantes.\n",
    "\n",
    "**Ejemplo:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resumen con valores atípicos:\n",
      "              Ventas\n",
      "count      4.000000\n",
      "mean    2650.000000\n",
      "std     4900.680225\n",
      "min      100.000000\n",
      "25%      175.000000\n",
      "50%      250.000000\n",
      "75%     2725.000000\n",
      "max    10000.000000\n"
     ]
    }
   ],
   "source": [
    "# Agregar valores atípicos y generar el resumen\n",
    "df['Ventas'] = [100, 200, 300, 10000]\n",
    "resumen_outlier = df.describe()\n",
    "\n",
    "print(\"Resumen con valores atípicos:\\n\", resumen_outlier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **3. Validación de Datos**\n",
    "Verifica si las características de los datos coinciden con las expectativas iniciales.\n",
    "\n",
    "**Ejemplo:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resumen de datos categóricos:\n",
      "        Nombre Departamento\n",
      "count       3            3\n",
      "unique      3            1\n",
      "top      Juan       Ventas\n",
      "freq        1            3\n"
     ]
    }
   ],
   "source": [
    "# Confirmar si los datos categóricos tienen la cantidad esperada de categorías únicas\n",
    "resumen_categorico = df.describe(include=['object'])\n",
    "\n",
    "print(\"Resumen de datos categóricos:\\n\", resumen_categorico)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2.7.2 Resúmenes Estadísticos Básicos para Columnas Numéricas**\n",
    "\n",
    "El método `describe` en Pandas proporciona un resumen estadístico clave para columnas numéricas. Este resumen incluye métricas básicas y avanzadas que permiten analizar rápidamente la distribución y características de los datos.\n",
    "\n",
    "### **Métricas Incluidas**\n",
    "1. **Recuento (`count`)**: Número de valores no nulos en la columna.\n",
    "2. **Promedio (`mean`)**: Media aritmética de los valores.\n",
    "3. **Desviación Estándar (`std`)**: Mide la dispersión de los datos respecto al promedio.\n",
    "4. **Mínimo y Máximo (`min`, `max`)**: Valores extremos en la columna.\n",
    "5. **Percentiles (25%, 50%, 75%)**: Dividen los datos en cuartiles principales.\n",
    "6. **Rango (`range`)**: Diferencia entre el valor máximo y mínimo.\n",
    "7. **Mediana (`median`)**: Valor central de la distribución.\n",
    "8. **Varianza (`var`)**: Mide la dispersión cuadrática respecto a la media.\n",
    "9. **Coeficiente de Variación (`std / mean`)**: Relación entre la desviación estándar y la media, útil para comparar la variabilidad entre columnas.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Recuento (`count`)**\n",
    "\n",
    "El `count` muestra el número de valores no nulos en una columna. Es útil para identificar columnas con valores faltantes o para verificar la cantidad de datos disponibles.\n",
    "\n",
    "**Definición:**  \n",
    "`dataframe['columna'].count()`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un DataFrame de ejemplo\n",
    "data = {'Ventas': [100, 200, 300, None], 'Descuentos': [5, 10, None, 20]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Calcular el recuento\n",
    "recuento = df['Ventas'].count()\n",
    "\n",
    "print(\"Recuento de valores no nulos en 'Ventas':\", recuento)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Promedio (`mean`)**\n",
    "\n",
    "El `mean` calcula la media aritmética de los valores en una columna. Es útil para identificar el centro de la distribución de los datos.\n",
    "\n",
    "**Definición:**  \n",
    "`dataframe['columna'].mean()`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular el promedio de la columna 'Ventas'\n",
    "promedio = df['Ventas'].mean()\n",
    "\n",
    "print(\"Promedio de 'Ventas':\", promedio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Desviación Estándar (`std`)**\n",
    "\n",
    "El `std` mide la dispersión de los valores respecto al promedio. Valores más altos indican mayor variabilidad en los datos.\n",
    "\n",
    "**Definición:**  \n",
    "`dataframe['columna'].std()`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular la desviación estándar de la columna 'Ventas'\n",
    "desviacion_estandar = df['Ventas'].std()\n",
    "\n",
    "print(\"Desviación estándar de 'Ventas':\", desviacion_estandar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Mínimo y Máximo (`min`, `max`)**\n",
    "\n",
    "- **`min`:** Encuentra el valor mínimo en una columna.\n",
    "- **`max`:** Encuentra el valor máximo en una columna.\n",
    "\n",
    "**Definición:**  \n",
    "`dataframe['columna'].min()`  \n",
    "`dataframe['columna'].max()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular el mínimo y máximo de la columna 'Ventas'\n",
    "minimo = df['Ventas'].min()\n",
    "maximo = df['Ventas'].max()\n",
    "\n",
    "print(\"Mínimo de 'Ventas':\", minimo)\n",
    "print(\"Máximo de 'Ventas':\", maximo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Percentiles (25%, 50%, 75%)**\n",
    "\n",
    "Los percentiles dividen los datos en partes iguales, mostrando los valores en el 25%, 50% (mediana) y 75% de la distribución.\n",
    "\n",
    "**Definición:**  \n",
    "`dataframe['columna'].quantile([0.25, 0.5, 0.75])`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular los percentiles de la columna 'Ventas'\n",
    "percentiles = df['Ventas'].quantile([0.25, 0.5, 0.75])\n",
    "\n",
    "print(\"Percentiles de 'Ventas':\\n\", percentiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Rango (`range`)**\n",
    "\n",
    "El rango mide la amplitud de los datos, calculando la diferencia entre el valor máximo y el mínimo en una columna. Es útil para entender la extensión total de la distribución.\n",
    "\n",
    "**Definición:**  \n",
    "`dataframe['columna'].max() - dataframe['columna'].min()`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular el rango de la columna 'Ventas'\n",
    "rango = df['Ventas'].max() - df['Ventas'].min()\n",
    "\n",
    "print(\"Rango de 'Ventas':\", rango)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Mediana (`median`)**\n",
    "\n",
    "La mediana representa el valor central de la distribución cuando los datos están ordenados. Es menos sensible a valores atípicos que el promedio.\n",
    "\n",
    "**Definición:**  \n",
    "`dataframe['columna'].median()`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular la mediana de la columna 'Ventas'\n",
    "mediana = df['Ventas'].median()\n",
    "\n",
    "print(\"Mediana de 'Ventas':\", mediana)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Varianza (`var`)**\n",
    "\n",
    "La varianza mide la dispersión cuadrática de los datos respecto al promedio. Valores más altos indican mayor dispersión.\n",
    "\n",
    "**Definición:**  \n",
    "`dataframe['columna'].var()`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular la varianza de la columna 'Ventas'\n",
    "varianza = df['Ventas'].var()\n",
    "\n",
    "print(\"Varianza de 'Ventas':\", varianza)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Coeficiente de Variación (`std / mean`)**\n",
    "\n",
    "El coeficiente de variación es la relación entre la desviación estándar y la media. Es útil para comparar la variabilidad relativa entre columnas o datasets.\n",
    "\n",
    "**Definición:**  \n",
    "`dataframe['columna'].std() / dataframe['columna'].mean()`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular el coeficiente de variación de la columna 'Ventas'\n",
    "coef_var = df['Ventas'].std() / df['Ventas'].mean()\n",
    "\n",
    "print(\"Coeficiente de variación de 'Ventas':\", coef_var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Tabla Resumen: Resúmenes Estadísticos Básicos (Ampliado)**\n",
    "\n",
    "| **Métrica**            | **Descripción**                                     | **Ejemplo**                          |\n",
    "|-------------------------|-----------------------------------------------------|--------------------------------------|\n",
    "| `count`                | Número de valores no nulos.                         | `df['Ventas'].count()`              |\n",
    "| `mean`                 | Promedio aritmético de los valores.                 | `df['Ventas'].mean()`               |\n",
    "| `std`                  | Dispersión respecto al promedio.                    | `df['Ventas'].std()`                |\n",
    "| `min` y `max`          | Valores mínimo y máximo en la columna.              | `df['Ventas'].min()`, `max()`       |\n",
    "| Percentiles            | Valores en el 25%, 50% (mediana), y 75%.            | `df['Ventas'].quantile([0.25])`     |\n",
    "| `range`                | Diferencia entre el valor máximo y mínimo.          | `df['Ventas'].max() - .min()`       |\n",
    "| `median`               | Valor central de la distribución.                   | `df['Ventas'].median()`             |\n",
    "| `var`                  | Dispersión cuadrática respecto al promedio.         | `df['Ventas'].var()`                |\n",
    "| `std / mean`           | Relación entre la desviación estándar y la media.   | `df['Ventas'].std() / .mean()`      |\n",
    "\n",
    "### **Conclusión General**\n",
    "\n",
    "El método `describe` y las métricas adicionales proporcionan una base sólida para analizar columnas numéricas en Pandas. Estas herramientas permiten:\n",
    "1. **Comprender la Distribución:** Métricas como el promedio, mediana y percentiles ayudan a identificar el centro y la dispersión de los datos.\n",
    "2. **Detectar Problemas:** Indicadores como el rango, desviación estándar y varianza resaltan valores atípicos o distribuciones inusuales.\n",
    "3. **Comparar Columnas:** El coeficiente de variación facilita la comparación de la variabilidad entre diferentes columnas o datasets.\n",
    "\n",
    "Estas estadísticas son fundamentales para el análisis exploratorio y la preparación de datos, ayudándote a tomar decisiones informadas antes de realizar análisis más avanzados.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2.7.3 Resúmenes de Datos Categóricos**\n",
    "\n",
    "El método `describe` en Pandas también genera resúmenes estadísticos para columnas categóricas. Estas métricas son útiles para comprender la distribución y características de los datos no numéricos, como texto o etiquetas.\n",
    "\n",
    "### **Métricas Principales**\n",
    "1. **Recuento (`count`)**: Número de valores no nulos.\n",
    "2. **Valores Únicos (`unique`)**: Número de categorías únicas en la columna.\n",
    "3. **Frecuencia del Valor Más Común (`freq`)**: Número de veces que aparece el valor más frecuente.\n",
    "4. **Valor Más Frecuente (`top`)**: Valor que aparece con mayor frecuencia en la columna.\n",
    "\n",
    "Estas métricas son fundamentales para analizar datos categóricos, identificar patrones y detectar problemas como valores atípicos o etiquetas inconsistentes.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Recuento (`count`)**\n",
    "\n",
    "El `count` muestra el número de valores no nulos en una columna categórica. Es útil para identificar cuántos datos válidos hay en una columna específica.\n",
    "\n",
    "**Definición:**  \n",
    "`dataframe['columna'].count()`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un DataFrame de ejemplo\n",
    "data = {'Categoría': ['A', 'B', 'A', None, 'C']}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Calcular el recuento de valores no nulos\n",
    "recuento = df['Categoría'].count()\n",
    "\n",
    "print(\"Recuento de valores no nulos en 'Categoría':\", recuento)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Valores Únicos (`unique`)**\n",
    "\n",
    "El `unique` devuelve el número de categorías únicas en una columna. Es útil para identificar la diversidad de valores en una columna categórica.\n",
    "\n",
    "**Definición:**  \n",
    "`dataframe['columna'].nunique()`  \n",
    "`dataframe['columna'].unique()`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular el número de categorías únicas\n",
    "num_categorias = df['Categoría'].nunique()\n",
    "\n",
    "# Listar las categorías únicas\n",
    "categorias_unicas = df['Categoría'].unique()\n",
    "\n",
    "print(\"Número de categorías únicas en 'Categoría':\", num_categorias)\n",
    "print(\"Categorías únicas:\\n\", categorias_unicas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Frecuencia del Valor Más Común (`freq`)**\n",
    "\n",
    "El `freq` muestra cuántas veces aparece el valor más frecuente en una columna categórica. Esto ayuda a identificar categorías dominantes o patrones comunes.\n",
    "\n",
    "**Definición:**  \n",
    "`dataframe['columna'].value_counts().iloc[0]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular la frecuencia del valor más común\n",
    "frecuencia = df['Categoría'].value_counts().iloc[0]\n",
    "\n",
    "print(\"Frecuencia del valor más común en 'Categoría':\", frecuencia)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Valor Más Frecuente (`top`)**\n",
    "\n",
    "El `top` devuelve el valor más frecuente en una columna categórica. Es útil para identificar la categoría dominante en los datos.\n",
    "\n",
    "**Definición:**  \n",
    "`dataframe['columna'].value_counts().idxmax()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular el valor más frecuente\n",
    "valor_top = df['Categoría'].value_counts().idxmax()\n",
    "\n",
    "print(\"Valor más frecuente en 'Categoría':\", valor_top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Tabla Resumen: Resúmenes de Datos Categóricos**\n",
    "\n",
    "| **Métrica**       | **Descripción**                                   | **Ejemplo**                                  |\n",
    "|--------------------|---------------------------------------------------|---------------------------------------------|\n",
    "| `count`           | Número de valores no nulos.                       | `df['Categoría'].count()`                   |\n",
    "| `unique`          | Devuelve las categorías únicas.                   | `df['Categoría'].unique()`                  |\n",
    "| `nunique`         | Número de categorías únicas.                      | `df['Categoría'].nunique()`                 |\n",
    "| `freq`            | Frecuencia del valor más común.                   | `df['Categoría'].value_counts().iloc[0]`   |\n",
    "| `top`             | Valor más frecuente en la columna.                | `df['Categoría'].value_counts().idxmax()`   |\n",
    "\n",
    "### **Conclusión**\n",
    "\n",
    "El análisis de datos categóricos con `describe` es esencial para:\n",
    "1. **Comprender la Distribución:** Identificar las categorías más comunes y su frecuencia.\n",
    "2. **Detectar Problemas:** Identificar valores atípicos, etiquetas inconsistentes o datos faltantes.\n",
    "3. **Preparar Datos:** Obtener insights sobre la diversidad de valores en columnas categóricas.\n",
    "\n",
    "Estas métricas proporcionan una visión clara y detallada de las características de los datos no numéricos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2.7.4 Personalización del Análisis**\n",
    "\n",
    "El método `describe` en Pandas permite personalizar los resúmenes generados mediante parámetros adicionales. Estas opciones permiten ajustar el análisis a necesidades específicas, enfocándose en ciertos tipos de datos o ajustando las métricas calculadas.\n",
    "\n",
    "### **Opciones Principales**\n",
    "1. **`percentiles`:** Define los percentiles que se deben calcular (por defecto, 25%, 50%, 75%).\n",
    "2. **`include`:** Especifica los tipos de columnas a incluir en el análisis.\n",
    "   - **`include='all'`:** Incluye todas las columnas, tanto numéricas como categóricas.\n",
    "   - **`include=[tipo]`:** Filtra por tipos de datos específicos, como `number` o `category`.\n",
    "3. **`exclude`:** Excluye ciertos tipos de columnas del análisis, como columnas categóricas o booleanas.\n",
    "\n",
    "Estas opciones proporcionan un control granular sobre los resúmenes generados, adaptándolos al contexto y necesidades del análisis.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **`percentiles`**\n",
    "\n",
    "El parámetro `percentiles` permite personalizar qué percentiles deben calcularse al generar el resumen estadístico. Por defecto, se calculan los percentiles 25%, 50% (mediana) y 75%.\n",
    "\n",
    "**Definición:**  \n",
    "`dataframe.describe(percentiles=[valores])`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un DataFrame de ejemplo\n",
    "data = {'Ventas': [100, 200, 300, 400, 500]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Personalizar los percentiles calculados\n",
    "resumen_percentiles = df.describe(percentiles=[0.1, 0.5, 0.9])\n",
    "\n",
    "print(\"Resumen con percentiles personalizados:\\n\", resumen_percentiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **`include`**\n",
    "\n",
    "El parámetro `include` permite especificar qué tipos de columnas deben incluirse en el análisis. Esto es útil para filtrar columnas categóricas, numéricas o de otros tipos específicos.\n",
    "\n",
    "**Definición:**  \n",
    "`dataframe.describe(include=[tipos])`\n",
    "\n",
    "**Opciones Comunes:**\n",
    "- **`include='all'`:** Incluye todas las columnas del DataFrame.\n",
    "- **`include=['number']`:** Solo analiza columnas numéricas.\n",
    "- **`include=['object']`:** Solo analiza columnas categóricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar resumen solo para columnas numéricas\n",
    "resumen_numerico = df.describe(include=['number'])\n",
    "\n",
    "print(\"Resumen de columnas numéricas:\\n\", resumen_numerico)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **`exclude`**\n",
    "\n",
    "El parámetro `exclude` excluye ciertos tipos de columnas del análisis, eliminándolas del resumen generado.\n",
    "\n",
    "**Definición:**  \n",
    "`dataframe.describe(exclude=[tipos])`\n",
    "\n",
    "**Opciones Comunes:**\n",
    "- **`exclude=['number']`:** Excluye columnas numéricas.\n",
    "- **`exclude=['object']`:** Excluye columnas categóricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un DataFrame con datos mixtos\n",
    "data = {'Ventas': [100, 200, 300], 'Categoría': ['A', 'B', 'C']}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Excluir columnas categóricas del análisis\n",
    "resumen_excluido = df.describe(exclude=['object'])\n",
    "\n",
    "print(\"Resumen excluyendo columnas categóricas:\\n\", resumen_excluido)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Tabla Resumen: Personalización del Análisis**\n",
    "\n",
    "| **Parámetro**   | **Descripción**                                    | **Ejemplo**                                  |\n",
    "|------------------|----------------------------------------------------|---------------------------------------------|\n",
    "| `percentiles`   | Personaliza qué percentiles incluir en el análisis. | `df.describe(percentiles=[0.1, 0.9])`       |\n",
    "| `include`       | Especifica los tipos de columnas a incluir.         | `df.describe(include=['number'])`           |\n",
    "| `exclude`       | Excluye tipos específicos de columnas del análisis.| `df.describe(exclude=['object'])`           |\n",
    "\n",
    "### **Conclusión**\n",
    "\n",
    "La personalización del método `describe` en Pandas permite ajustar el análisis a las necesidades específicas del usuario:\n",
    "- **`percentiles`** para ajustar los puntos clave de la distribución que se muestran.\n",
    "- **`include`** y **`exclude`** para filtrar los tipos de columnas relevantes para el análisis.\n",
    "\n",
    "Estas herramientas hacen que `describe` sea aún más flexible y adaptativo para diferentes contextos de análisis.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **2.8 Exportar Resultados**\n",
    "\n",
    "En cualquier flujo de trabajo de análisis de datos, llega un momento en el que los resultados necesitan ser guardados o compartidos. Pandas proporciona herramientas versátiles para exportar DataFrames a diversos formatos, como CSV y Excel, lo que facilita la integración con otras herramientas, la documentación del trabajo y la distribución de informes.\n",
    "\n",
    "### **¿Por qué es importante exportar resultados?**\n",
    "1. **Colaboración:** Permite compartir análisis y resultados con equipos de trabajo o stakeholders.\n",
    "2. **Integración:** Los formatos de exportación son compatibles con otras herramientas como Excel, bases de datos y sistemas de gestión.\n",
    "3. **Almacenamiento:** Guardar los datos en formatos comunes asegura la persistencia y accesibilidad futura.\n",
    "\n",
    "### **¿Qué aprenderás en este submódulo?**\n",
    "1. Cómo exportar DataFrames a archivos **CSV** y **Excel**, ajustando detalles como la inclusión de índices y separadores.\n",
    "2. Cómo aprovechar opciones avanzadas como el uso de múltiples hojas en Excel o la definición de codificaciones para archivos con caracteres especiales.\n",
    "3. Las mejores prácticas para elegir el formato adecuado según el contexto del análisis o los requisitos del proyecto.\n",
    "\n",
    "Este submódulo te permitirá dominar las opciones de exportación en Pandas para facilitar la transición de los resultados desde el análisis al mundo real."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2.8.1 Exportar a Archivos CSV (`to_csv`)**\n",
    "\n",
    "El método `to_csv` guarda el contenido del DataFrame en un archivo CSV (Comma-Separated Values). Este formato es ampliamente utilizado por su simplicidad y compatibilidad con otras herramientas de análisis.\n",
    "\n",
    "**Definición:**  \n",
    "`dataframe.to_csv('nombre_archivo.csv', index=True, sep=',')`\n",
    "\n",
    "**Parámetros Clave:**\n",
    "- **`index`:** Si es `True` (por defecto), incluye el índice en el archivo.\n",
    "- **`sep`:** Define el separador entre valores (por defecto, `','`).\n",
    "- **`header`:** Especifica si los nombres de las columnas se incluirán en el archivo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un DataFrame de ejemplo\n",
    "data = {'Producto': ['A', 'B', 'C'], 'Ventas': [100, 200, 300]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Exportar a un archivo CSV sin incluir el índice\n",
    "df.to_csv('ventas.csv', index=False)\n",
    "\n",
    "print(\"El DataFrame ha sido exportado a 'ventas.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2.8.2 Exportar a Archivos Excel (`to_excel`)**\n",
    "\n",
    "El método `to_excel` guarda el contenido del DataFrame en un archivo Excel. Este formato es ideal para informes y análisis más complejos.\n",
    "\n",
    "**Definición:**  \n",
    "`dataframe.to_excel('nombre_archivo.xlsx', index=True, sheet_name='Hoja1')`\n",
    "\n",
    "**Parámetros Clave:**\n",
    "- **`index`:** Si es `True` (por defecto), incluye el índice en el archivo.\n",
    "- **`sheet_name`:** Define el nombre de la hoja donde se guardará el DataFrame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exportar a un archivo Excel\n",
    "df.to_excel('ventas.xlsx', index=False, sheet_name='Ventas')\n",
    "\n",
    "print(\"El DataFrame ha sido exportado a 'ventas.xlsx'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2.8.3 Opciones Avanzadas**\n",
    "\n",
    "Pandas permite personalizar aún más la exportación mediante opciones avanzadas:\n",
    "1. **Separadores Personalizados (`sep`)** en CSV.\n",
    "   - Ejemplo: Usar `';'` en lugar de `','` como separador.\n",
    "2. **Exportar a Múltiples Hojas** en Excel utilizando `ExcelWriter`.\n",
    "   - Ideal para guardar diferentes DataFrames en el mismo archivo.\n",
    "3. **Codificación (`encoding`)** para manejar caracteres especiales.\n",
    "   - Por defecto, utiliza `utf-8`.\n",
    "\n",
    "### **Exportar a Múltiples Hojas en Excel**\n",
    "Puedes usar `ExcelWriter` para escribir varios DataFrames en un archivo Excel con diferentes hojas.\n",
    "\n",
    "**Definición:**  \n",
    "`with pd.ExcelWriter('archivo.xlsx') as writer:`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear otro DataFrame para múltiples hojas\n",
    "df_ventas = pd.DataFrame({'Producto': ['A', 'B'], 'Ventas': [100, 200]})\n",
    "df_descuentos = pd.DataFrame({'Producto': ['A', 'B'], 'Descuento': [10, 20]})\n",
    "\n",
    "# Exportar a un archivo Excel con múltiples hojas\n",
    "with pd.ExcelWriter('reporte.xlsx') as writer:\n",
    "    df_ventas.to_excel(writer, sheet_name='Ventas', index=False)\n",
    "    df_descuentos.to_excel(writer, sheet_name='Descuentos', index=False)\n",
    "\n",
    "print(\"El archivo 'reporte.xlsx' con múltiples hojas ha sido exportado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Tabla Resumen: Métodos de Exportación**\n",
    "\n",
    "| **Método**       | **Formato**                | **Descripción**                                            | **Ejemplo**                           |\n",
    "|-------------------|---------------------------|------------------------------------------------------------|---------------------------------------|\n",
    "| `to_csv`         | CSV                        | Guarda el DataFrame en un archivo CSV.                     | `df.to_csv('archivo.csv')`            |\n",
    "| `to_excel`       | Excel                      | Guarda el DataFrame en un archivo Excel.                   | `df.to_excel('archivo.xlsx')`         |\n",
    "| `ExcelWriter`    | Excel (Múltiples Hojas)    | Permite guardar varios DataFrames en un solo archivo Excel.| `ExcelWriter('archivo.xlsx')`         |\n",
    "\n",
    "### **Conclusión**\n",
    "\n",
    "La capacidad de exportar resultados es esencial para compartir datos o integrarlos en flujos de trabajo externos.  \n",
    "- Usa **`to_csv`** para exportar datos en un formato simple y compatible.  \n",
    "- Usa **`to_excel`** para generar informes más elaborados, incluyendo múltiples hojas.  \n",
    "- Aprovecha las opciones avanzadas para personalizar la salida según las necesidades específicas.\n",
    "\n",
    "Estas herramientas hacen que Pandas sea altamente adaptable y práctico para la distribución de resultados.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
